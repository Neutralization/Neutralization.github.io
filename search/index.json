[{"content":"最开始给哔哩哔哩周刊写自动化脚本的时候，还不觉得生成图片能遇到什么坑。毕竟之前也用过 Pillow 库，算是比较熟悉了。而且遇到的都是些在普通不过的正常文本。\n直到躲不开的 emoji 开始出现了。\n一些普通的 Emoji ☀☁☂☃☄☎☑☔☕☘\n刚开始遇到这类也还好，因为很显然，只是文本的字体没有这部分 emoji，Pillow 就全部给显示成了方框。简单框了个范围，用另一个字体来渲染就是了。\n但后来就开始遇到各种标题里的花活，什么上下标字符花体字粗斜体全来了。比如\n【𝟒𝐊 𝟔𝟎𝐅𝐏𝐒】这首《𝑭𝒂𝒍𝒍𝒊𝒏𝒈 𝑨𝒈𝒂𝒊𝒏》如今治愈了多少人！！! ℳ₯㎕-沉 沦\n自此真正打响了与 Unicode 斗争的第一枪。\n一些普通的 Unicode 上下标字符花体字粗斜体也能接受，人家看起来至少还是个正经字符。解决方法也是一样的简单粗暴：找一个定义了这部分字符的字体，单独匹配渲染。\n于是脚本里的 UnicodeA_F 慢慢增加到了 UnicodeD_F。划一个新的正则范围，匹配上一个新的字体，如此查漏补缺的工作也还能接受，毕竟遇到特殊字符的场合相对还是非常有限的。\n直到真正的重量级上场了。\nCombining 字符 ✥我҉͛̀̈̈̾̓̀͂̊͝的模҉̖̭̱͍̩͕͓̋̓͋̈̑͋̉͢͞ͅ样吓҈̎̍̅̒̎͂̈́̚͞.到你҈̛́̐̄́̃͗̓͒͒͊̿͛̒了？～❤✥\n只能承认它杀死了比赛。但其实类似的标题并不是第一次见，在更早之前，我算是见过它的一位大前辈：\n这位前辈更是重量级，即便在写这篇记录的时候，我也不得不佩服这种和视频契合的标题风格确实是非常到位。\n能做到这种效果的原因是由于其中大量的 Combining 字符，比如日文的清浊音符号，部分小语种的音标和一些独特的组词方式。\n但是 Pillow 罢工了呀，臣妾渲染不来，您还是另请高明吧。\n思来想去不得法，最后想到，那既然网页前端能够正常展示，应该可以通过无头浏览器前端渲染然后截屏的方式，把这些特殊字符正确的显示出来。\n简单糊了个页面，算是解决了这个问题。哔哩哔哩周刊与 Unicode 的斗争也算是告一段落了。\nMAD 周刊，新的挑战 接手开始MAD 周刊的自动化后，很快又不得不面对 Unicode 带来的问题。然而实际上，应该说是 Unicode 和 Adobe 共同带来的问题。\n为了保证原始 MAD 周刊工程文件的纯洁性，所有的文本都按照文本图层来进行修改。本来这也没有什么问题。\n但是原工程使用的大量表达式，是基于旧版的 ExtendScript 引擎，毕竟工程本身是 2016 年的产物。但之前做哔哩哔哩周刊时一直用的是 JavaScript 引擎的表达式，这就产生了几个问题：\n特殊的 Unicode 字符需要使用不同的字体才能正常显示 ExtendScript 不能修改文本图层的部分字体样式属性 相比 ExtendScript，JavaScript 能够修改字体字号颜色等属性 为了使用 JavaScript 引擎就要把整个工程的其他表达式全部重写 AfterEffects 对通过脚本修改字体的行为有奇怪的问题，不能保证正常显示 由于工作量太大，重写全部表达式显然不现实。基于此，我选择了另一种方式：让所有花活都变成正常的字符。\n这就需要有一个表来记录这些特殊字符应该被替换为具体哪一个字符，于是诞生了 Antimemetics-Division 这样一个对抗项目。\n期间则是枯燥的 Unicode 查表浏览过程，尽可能多的搜集这类特殊字符的标题来保证更广的覆盖面。\n而后 Emoji 的问题也需要处理，这就要划分 Emoji 的 Unicode 字符范围。幸好这部分有据可查，在 Unicode 官方规范中有详细的记录各个 Emoji。\nCombining 字符的问题也得到了解决，Unicode 官方规范中规定了 Mc Me Mn 三类 Mark 字符正好能够覆盖这个问题。\n最终 Antimemetics-Division 不负使命，让 MAD 周刊中的标题都成为了“正经标题”，可喜可贺，可喜可贺。\n虽然留下了反向利用此项目可以生成更加让人血压爆炸的标题的问题，暂且不提\n本可以更优雅的解决方式 如是几期视频更新后，我逐渐意识到一种割裂感。\n为什么哔哩哔哩周刊就应该渲染正常，MAD 周刊就要去掉这些字符呢？这种区别对待说白了，不过还是一种懒惰。\n不同于我最初承认 ATOLS 玩的一手好标题，在 MAD 周刊上我反而以字符论标题优劣，不应是正确的解法。\n于是决定同哔哩哔哩周刊一样通过前端截图来解决这个问题。同时考虑到排版影响，部分 MAD 标题常用全角符号，导致标题的起始像素位置其实并不顶格，便在脚本中加入了一个粗略的判断，进行一个 X 轴的移位使得视觉上显得更对齐一些。\n但 Emoji 还是给我捣了乱，Emoji 因为都是全角宽度，无法判断像素位置是否顶格，这个问题只能留到之后再寻找合适的解法了。\nUpdate 2022/10/03 成了，生成图片然后切左右透明像素就是了，问题解决（\n未尽之事 计划将哔哩哔哩周刊的图片生成也改为前端截图的方式。且不谈特殊字符的问题，前端这种方便可视化调整的形式，应该会对代码修改更友好一些，虽然想来是不会有什么改版和修改了。\n而且通过 CSS，还能够实现一些 Pillow 做不到的文本样式效果，更好的还原 PSD 的设计样式。\n曾经还想过写 Photoshop 脚本来做图，虽然还没试验过 Photoshop，考虑到前述 AfterEffects 文本图层的问题，以及前端截图确实更灵活，也就不再考虑了。\n","date":"2022-08-09T00:00:00Z","permalink":"https://naizi.ch/2022/08/09/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E5%92%8C-unicode-%E4%B8%8D%E6%96%AD%E4%BD%9C%E6%96%97%E4%BA%89%E7%9A%84%E6%97%A5%E5%AD%90/","title":"记录一些和 Unicode 不断作斗争的日子"},{"content":"准备工作 安装 WSL，不再赘述。\n移除 WSL 环境变量中包含的 Windows 路径，为编译做准备。\n打开 WSL 终端，新建/etc/wsl.conf文件，输入如下内容并保存。\n[interop] appendWindowsPath = false 然后执行wsl --shutdown，再重新启动 wsl，执行echo ${PATH}检查是否含有 Windows 路径。\n更新系统\nsudo apt update\nsudo apt full-upgrade -y\n准备编译工具\nsudo apt install -y ack antlr3 asciidoc autoconf automake \\\nautopoint binutils bison build-essential bzip2 ccache cmake cpio \\\ncurl device-tree-compiler fastjar flex gawk gettext gcc-multilib \\\ng++-multilib git gperf haveged help2man intltool libc6-dev-i386 \\\nlibelf-dev libglib2.0-dev libgmp3-dev libltdl-dev libmpc-dev libmpfr-dev \\\nlibncurses5-dev libncursesw5-dev libreadline-dev libssl-dev libtool \\\nlrzsz mkisofs msmtp nano ninja-build p7zip p7zip-full patch pkgconf \\\npython2.7 python3 python3-pip qemu-utils rsync scons squashfs-tools \\\nsubversion swig texinfo uglifyjs upx-ucl unzip vim wget xmlto xxd zlib1g-dev\n克隆仓库 下载 OpenWrt 源码（更改为LEDE）\ncd ~ git clone https://github.com/coolsnowwolf/lede openwrt cd openwrt git pull 下载 OpenClash 源码\ncd ~/openwrt/ mkdir package/luci-app-openclash cd package/luci-app-openclash git init git remote add origin https://github.com/vernesong/OpenClash.git git config core.sparsecheckout true echo \u0026#34;luci-app-openclash\u0026#34; \u0026gt;\u0026gt; .git/info/sparse-checkout git pull --depth 1 origin master git branch --set-upstream-to=origin/master master 修改路由 IP 地址\n\u0026gt; sed -i \u0026#39;s/192.168.1.1/192.168.2.1/g\u0026#39; package/base-files/files/bin/config_generate 开始编译 更新 feeds\ncd ~/openwrt/\n./scripts/feeds update -a\n./scripts/feeds install -a\n选择编译内容\ncd ~/openwrt/\nmake defconfig\nmake menuconfig\n./scripts/diffconfig.sh \u0026gt; diffconfig\ndiffconfig 后期可用于更新镜像时导入\ncp diffconfig ~/openwrt/.config\nmake defconfig\nmake menuconfig\nTarget System ---\u0026gt; (X) Rockchip Subtarget ---\u0026gt; (X) RK33xx boards (64 bit) Target Profile ---\u0026gt; (X) FriendlyARM NanoPi R2S Target Images ---\u0026gt; [*] ext4 [*] squashfs [*] GZip images (128) Kernel partition size (in MB) (2048) Root filesystem partition size (in MB) Kernel modules ---\u0026gt; Cryptographic API modules ---\u0026gt; ALL LuCI ---\u0026gt; 2. Modules ---\u0026gt; Translations ---\u0026gt; \u0026lt;*\u0026gt; Simplified Chinese (zh-cn) \u0026lt;*\u0026gt; luci-compat 3. Applications ---\u0026gt; \u0026lt;*\u0026gt; luci-app-openclash \u0026lt;*\u0026gt; luci-app-turboacc \u0026lt;*\u0026gt; luci-app-unblockmusic [*] UnblockNeteaseMusic NodeJS Version \u0026lt;*\u0026gt; luci-app-wireguard \u0026lt;*\u0026gt; luci-app-zerotier 4. Themes ---\u0026gt; \u0026lt;*\u0026gt; luci-theme-argon Utilities ---\u0026gt; Editors ---\u0026gt; \u0026lt;*\u0026gt; nano-full 执行编译\ncd ~/openwrt/\nmake -j8 download\nmake -j8\n编译生成的镜像文件在 ~/openwrt/bin/targets/rockchip/armv8/ 路径下\n收尾工作 opkg 安装部分官方包的时候会提示 Kernel 版本不对kernel is not compatible，这是因为自己编译的 kernel 指纹和官方不一致造成的，替换成官方指纹即可。\n比如目前 kernel 版本是5.4.143-1-fb881fbbae69f30da18e7c6eb01310c1\nsed -i s/编译的kernel hash/fb881fbbae69f30da18e7c6eb01310c1/g /usr/lib/opkg/status\nEOF 编译 run 了一万年，再不写点什么记下来，下次编译根本记不住了.jpg\n后来参考学习了 P3TERX 的 这篇文章 利用 Github Action 进行编译，并且按照 LEDE 的这个 PR 打开了缓存工具链，再也不用面对奇怪的环境问题和该参数重编又是四、五个小时的窘境了。\n","date":"2021-10-05T00:00:00Z","permalink":"https://naizi.ch/2021/10/05/openwrt-%E6%8A%98%E8%85%BE%E7%AC%94%E8%AE%B0/","title":"OpenWrt 折腾笔记"},{"content":"Ender 3 不愧是创想三维家的经典款 3D 打印机，一直没关注产品消息，不知道什么时候已经出了 V2 款了。\n买当然是不会买的，原来的版本还是挺好用，购买的时候正好京东打折，当时 1k 出头的价格还是很香的。\n买来时间也有点久了，考虑升级一下固件，但是官方并没有提供这一款的后续固件升级，也没有相关教程。搜索了一下发现还需要自行刷入 bootloader 后才能刷写固件，看来是当时就没有考虑用户侧的后续升级。\n升级固件的想法主要是因为看到了 OctoPrint，一个利用树莓派控制和实时监控 3D 打印机的项目。\n刷写 bootloader 主要是跟着Bootloader Flashing Guide这篇文章中的指导。因为主板芯片是 1284P，和其他打印机的刷写存在区别，建议直接下载链接中的刷写包来操作。\n概括的来讲，需要 Arduino 开发板作为中介，与打印机主板的刷写接口连接，再通过 Arduino IDE 将 bootloader 引导程序由 Arduino 刷写到打印机主板芯片上。\n找同事借了一块 Arduino MEGA 2560 和几根杜邦线，因为 Arduino 的不同版本引脚定义几乎没有区别，也不是一定要用 Arduino Uno。\n完成这一步后，打印机有了 bootloader，就可以方便的进行固件升级操作了。\n编译固件并上传至打印机 TH3D 给出了 Ender 3 的完整固件升级流程。\n真的是个不错的网站，除了 Creality 还有其他很多常见 3D 打印机厂家不同型号的操作教程。根据教程描述，安装 VSCode，编译固件上传即可，实际操作中我也完全没有遇到阻碍，非常顺利的编译上传完成了，见到了启动画面的 TH3D 标志 logo。除了界面是全英文，但这也并不影响机上操作。\nOctoPrint 远程打印 又是一个利用树莓派的项目，于是我的树莓派又经历了一次 SD 卡格式化重写映像。\n同样也是完全跟随教程操作，在树莓派上使用 OctoPrint 映像，连接 WiFi，USB 连接打印机。\n教程中还提供了一套用于固定树莓派摄像机的 3D 打印文件，可以固定在打印机 X 轴上用来监测打印状态。也可以选择使用普通的 USB 摄像头，但是架设摄像头的方式就要靠自己另外实现了。\n正好很早以前买过一个树莓派专用摄像头，这就给它用上了。\nFinish 一切设置好，https 访问树莓派 IP 或者 https://octopi.local/ ，如果摄像头正常的话，就能看到打印状态了。\n界面里可以一览无余的看到打印机当前的喷嘴和热床温度，打印状态，Gcode 图示等等。也可以直接通过网页上传 Gcode 文件直接打印，由于是通过 USB 连接到打印机，免去了反复插拔 SD 卡传输文件的步骤，真的是方便了很多。\nOctoPrint 还提供视频录制，开启后可以录制打印过程中的摄像头画面，生成延时视频。\n","date":"2021-08-28T00:00:00Z","permalink":"https://naizi.ch/2021/08/28/%E5%8D%87%E7%BA%A7-3d-%E6%89%93%E5%8D%B0%E6%9C%BA%E5%9B%BA%E4%BB%B6%E5%8F%8A%E8%BF%9C%E7%A8%8B%E6%89%93%E5%8D%B0%E6%96%B9%E6%A1%88/","title":"升级 3D 打印机固件及远程打印方案"},{"content":"2 月的时候，群友看 VTB 直播雀魂，发现主播为了防止互动的时候窥屏看到手牌，PS 了一张看起来像手牌的图来挡住真实的手牌。\n群友受此启发，纷纷讨论自己也要这么玩，PS 各种役种的牌扮老虎，比如大家都喜欢的国士无双：\n大家云集响应，因为之前正好写过生成器，趁此机会我就说群友要啥我就帮群友 PS，都可以做。后来群友觉得正经的役没意思，想搞点不一样的，说要搞个圆周率。这就有意思了。话题很自然的转到了那能不能胡牌的问题上，因为只有数字，先默认牌型是清一色，一试，发现小数点后最开始的 14 位数字就真的能凑成一副胡牌：\n3.14159265358979 -\u0026gt; 234 678 555 999 11\n我立刻兴致来了，马上就想看看位数再往后，还能有哪里能凑成胡牌，这就开始写脚本。\n圆周率位数的迭代之前写飞花令的时候用过，Ctrl+V 过来，然后是判断是否和牌的算法。简单来说按照一般和牌的标准型n*AAA+m*ABC+DD=14，通过先取雀头DD，然后交换先取刻子AAA后顺子ABC或者先顺子后刻子的逻辑迭代完整副手牌，看残张是否为零就能确认这副手牌是否和牌。\n写完代码，测试了几次，又另外加入了七对子牌型的判断，然后以一万位为目标执行了一遍。不出意料还真的有很多位置的数列能够凑成和牌。感觉这还是值得做个视频记录一下。\n视频里只迭代了小数点后一万位的数字。在测试脚本的时候，其实试验过迭代到二十万位，已经相当耗时了，不过也因此遇到了一些比较值得一说的牌型：\n比如遇到的第一个平和是在第 209 位小数，数列是7 5 6 6 5 9 3 3 4 4 6 1 2 8，牌型是66 123 345 456 789，还是一个一气贯通\n断幺九在第 222 位小数，数列是8 4 7 5 6 4 8 2 3 3 7 8 6 7，牌型是66 777 888 234 345\n四暗刻在第 5391 位小数，数列是8 8 2 8 1 6 1 3 3 2 3 1 6 6，牌型是22 111 333 666 888\n二杯口在第 15912 位小数，数列是8 5 7 4 5 6 9 8 1 4 7 1 9 6，牌型是11 456 456 789 789，这也是第一个七对子牌型（但规则只计算二杯口），下一个七对子牌型在 16834 位，但同样也是二杯口，再下一个则是 21513 的一色双龙会，国标役种。真正的七对子要到 35441 位才能遇到，6 4 6 4 5 5 1 2 7 8 1 2 7 8，牌型11 22 44 55 66 77 88\n一色双龙会在第 21513 位小数，数列是5 7 2 3 9 7 3 9 5 1 2 8 8 1，牌型是123 123 55 789 789\n九莲宝灯在第 32452 位小数，数列是9 2 1 9 5 1 9 6 7 5 1 4 8 3，牌型是111 234 55 678 999，还是个最漂亮的九莲宝灯。\n四暗刻绿一色在第 162552 位小数，数列是4 2 4 3 3 3 4 8 8 2 2 6 6 6，牌型是222 333 444 666 88，显然这还是个纯绿一色。\n最后回顾下一切的开端：\n","date":"2021-03-17T00:00:00Z","permalink":"https://naizi.ch/2021/03/17/%E5%9C%86%E5%91%A8%E7%8E%87%E9%87%8C%E7%9A%84%E9%BA%BB%E5%B0%86/","title":"圆周率里的麻将"},{"content":"总结一下周刊哔哩哔哩排行榜制作流程自动化过程中遇到的一些问题。\n之前的周刊制作过程中，组员各自领取不同部分的制作任务，每一部分的内容格式包含在不同的 yml 文件中。\n通常先把 yml 中的 av 号取出，去下载对应的视频到本地，然后人工浏览选择实际制作时选取的片段，记录下片段的开始时间，修改 yml 中的对应字段。然后上传修改完成的 yml，转换成之后导入 Vegas 时需要的 xml 文件。\n由于旧流程的局限性，没有考虑到视频尺寸的适配，因此在导入 Vegas 后，往往要手动对齐所有视频。另外由于不同部分的效果不一致（比如是否有过渡场景），也没有在 yml 中进行区分，往往还要再手动调整。工作量本质不大，但其实都是可以进行优化的场景。\n早几年的时候一直听说 Adobe After Effects 脚本如何如何强大，表达式如何如何好用。怎奈 javascript 从未接触，一直没能下决心去了解。这次也算是终于下了决心，开始了 AE 自动化制作周刊之路。\nVegas -\u0026gt; AfterEffects 流程整理 首先是重新整理一遍 Vegas 的工作流，尽可能符合原来人工的操作顺序，也方便我理清代码逻辑。\nVegas 的导入视频过程，使用的是 xml 还是 yml 文件其实没有本质的区别，需要的内容无非是导入哪个视频的哪个时间点，时长多久，视频如何定位到准确的位置，以及导入对应的图片素材，添加视频过渡效果等等。\n确定基本顺序后，我就开始对照 Adobe 的文档，一步步的编写代码。有一说一，Adobe 的文档确实非常详细，比 Vegas 的文档看起来是清晰多了（最初的确考虑过直接用 Vegas 脚本来做）。\n最初先写死了各种变量来进行调试，基本是写一行测试一行的方式。逐步学会了 AE 中如何使用脚本添加合成，再往合成中添加视频/图片层，调整视频的入点和出点等等。熟悉了之后，由于一个个视频的导入其实是非常模块化的操作，在复制粘贴了十几次代码后，我终于意识到应该把它抽象成函数调用。\n编写函数调用 流程已经很清晰了，也熟悉了代码，函数要实现的事情其实很简单：\n添加一个新图层，指定视频文件和时长节点 给视频图层添加时间出入点和过渡效果 给视频图层添加音频过渡效果 于是我分别编写了 AddLayer, AddVideoProperty, AddAudioProperty 三个函数，包装了 Adobe 的 layers.add 和 property.setValueAtTime 两个方法。\n在编写函数的过程中，因为是 Vegas-\u0026gt;AfterEffects 复刻，Vegas 中的过渡曲线我在 AE 中没有找到一致的傻瓜式功能，只能自己去实现曲线的效果。这里就遇到了 Adobe 文档“点到为止”的问题：它没有提供详细的示例代码。\n原本是计划使用 AE 表达式（区别于 AE 脚本）来实现的，但是文档中对于如何添加表达式并没有解释的很详细，Google 和 StackOverflow 也没能提供有价值的信息。反复翻阅文档之后，我决定采用其他的方式来实现：通过微分法添加透明度/音频增益关键帧来逼近曲线效果。\n于是 AddVideoProperty, AddAudioProperty 的主要代码就变成了基于三角函数的 property.setValueAtTime，复习正/余弦曲线方程的过程还真是有些令人怀念 (￣_,￣ )\n函数的函数 对单个视频的函数完成之后，意识到单个 yml 文件其实就是一个更大的函数。\n这时需要解决的就是之前提到的对于过渡场景有无的判断。为了能够将工作流无缝转换到 AE，此时不可能再对 yml 做新的要求，好在数量不多，这部分区别直接手工指定写死在代码中即可。\n同时为了减少重复的代码，将原本写在 AddVideoProperty 函数中的视频定位部分的代码放到了这个大函数 AddRankPart 中，通过 for 循环迭代 yml 列表（这时其实还是一个写死的列表，而不是读取 yml 文件）的数据，对视频进行长宽比的判断同比缩放，再定位至正确的坐标。\n另外为了兼容周刊的排名规则，即长期视频的出现会造成视频数量的变化，以及每部分排名中最后一个视频过渡效果与其他不同，和视频间是否需要过渡画面等做了相应的判断，最后通过额外的函数参数兼容了不同样式的榜单部分。\n但由于主榜前三实在比较特殊，就没有使用 AddRankPart 而是直接重写了一遍逻辑。\n插曲 在编写完整个自动化代码后，遇到了久未见到的视频源失效的特殊样式，需要在失效的视频上添加遮挡。Vegas 时期这也是靠人工完成的，因为失效视频已经极少遇到，采用的方案是添加一个 array 记录失效的视频，在 AddRankPart 的 for 循环中添加视频是否在 array 中的判断来解决。这就需要当出现此类情况的时候修改代码中的变量。\n但新增一个文件来记录也是同样要人工修改，罢了，就这样吧。\n定型文 榜单各个部分间的过渡画面都是不随榜单变化，或者素材文件名保持固定，这部分内容就直接使用 AddLayer, AddVideoProperty, AddAudioProperty 写死了逻辑和时间点。\n之后把写死的测试数据改写成读取实际的 yml 文件内容和素材文件，然后就是大量的 MagicNumber 时间点和不断地调试。为了测试兼容性还试验了 AfterEffects 的不同版本，结果发现不同版本的 AE 使用的 js 版本大相径庭，各种神秘问题频出。最后还是放弃了去追求更高的兼容性，优先保障了较新版本的 2019CC 和 2020CC 的使用。\nAfterEffects 的问题 音频处理 AE 作为视频软件，对音频的处理就显得较弱了，这本来不是什么大问题。\n但是上榜的视频各自的音频增益相差很大，最为明显的是 UP 主的投稿视频和 B 站番剧的动画，后者音频增益比前者低了一个等级。\nVegas 中可以直接通过“音频标准化”操作简单解决这个问题。AE 其实也可以通过 Adobe 家族的兼容性，将工程导出使用 Premiere 或者 Audition 进行音频标准化，但这样一来就失去了“自动化”的目的。\n那么有什么其他办法可以解决么？在咨询群友和同事的意见之后，ffmpeg-normalize进入了我的视野。\nffmpeg-normalize 简单而言，ffmpeg-normalize 是对 ffmpeg 中音量处理的一层包装，将整个过程自动化便于进行批量化的操作。\n试验之后发现果然方便，于是立刻开始编写代码。因为 CMD 过于简陋，选择了 powershell 来进行批处理。\n然而在试运行一周后，发现大文件处理效率是个问题。对于动辄 600MB~1G 的番剧区视频，ffmpeg-normalize 处理整个文件所消耗的时间甚至超过了最后 AE 导出视频的时间，这就比较难接受了。而且它也不支持只对视频/音频的某一部分进行标准化操作，非常尴尬。\nffmpeg 视频截取\u0026amp;音频处理 既然 ffmpeg-normalize 是 ffmpeg 的包装，自然想到了直接用 ffmpeg 不也可以吗？还能少装一个 python，降低了其他组员的学习成本。\n为了提升处理效率，与其处理整个视频，不如只处理选取的视频片段。于是在刚刚学习完 JavaScript 后，我又开始翻阅 powershell 的文档，研究怎样用 powershell 实现读取 yml 中的数据，传递给 ffmpeg 截取视频，并标准化截取视频的音频。\n这种不同语言间的语法差异着实又烦恼了我一阵子，好在微软的文档也很详尽，绕了几次弯路后找到了正确的写法，实现了需求。\n考虑到现在大家基本上都有不错的显卡，调用 ffmpeg 截取时使用 GPU 编/解码又能进一步提升效率，但使用 GPU 不能发挥 powershell 的并发能力，这受制于显卡的硬件，但仍比 CPU 编码快上不少。\n然而在音频标准化处理上，GPU 就没有用武之地了，只能依赖 CPU 处理，与此同时可以依靠 powershell 的 ForEach-Object -Parallel 并发加快处理速度。只能说这两者算是有失有得吧。\n对应修改 视频先行截取意味着之前 AE 脚本中读取的视频时间点全部无效了，于是修改了对应的变量在读取数据后直接重新赋值为零，纠正了时间问题。\nPowerShell 工作流 既然 powershell 并发这么好用，我又动了新的歪脑筋，想起了之前 python 写的 B 站视频下载工具。\n因为已经尝试重构过 bash 的代码，在熟悉了 powershell 的部分函数后，这部分重构也是轻车熟路。很快一个读取分析 yml 文件自动下载视频的 powershell 脚本就编写完成了。\n不仅并发下载的代码逻辑比 python 简洁多了，甚至又填坑了之前想要指定下载分 P 的 TODO。另外 python 版的代码在下载时调用了 aria2c，powershell 的重构中也放弃了这部分依赖，如此一来整个工作流的外部依赖就只有 ffmpeg 了。\n为了完全抛弃 python 脚本的依赖，周刊使用的生成传送门评论的脚本（没错，这个也是 python）当然也要用 powershell 重构，事情到了这一步已经无法停下脚步了（ry\n最后，download.ps1, normailze.ps1, rankdoor.ps1 组成了周刊自动化中 powershell 工作流的三剑客。\n未尽之事 如此一来，制作周刊还剩下的人工操作就只有选取视频片段一项了。但是这也已经有了尝试性的解决方案（Artificial Idiot 截取片段试运行），目前仍是个 python 脚本，也许成熟之后也会再重构为 powershell，到时就是四剑客了。\n如果你对以上内容有兴趣，相关脚本在 Github 已开源。如果你不知道周刊哔哩哔哩排行榜，你也可以选择关注了解一下。\nEOF powershell 真香（\n","date":"2021-03-07T00:00:00Z","permalink":"https://naizi.ch/2021/03/07/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%88%B6%E4%BD%9C%E5%91%A8%E5%88%8A%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E6%8E%92%E8%A1%8C%E6%A6%9C/","title":"自动化制作周刊哔哩哔哩排行榜"},{"content":"之前也有在尝试用 3D 打印做奇怪的东西，建模一直在用的是 AutoDesk 家的线上工具Tinkercad，属于那种拖拖拽拽就能拼出差不多模型的工具，还挺好用。\n这次尝试做小夜灯，原本是打算做成游戏关卡结算时的三星标志，后来想了想，为了更显而易见的突出方舟元素，用了游戏里医疗干员的标志。主要因为医疗干员的标志几何对称性很好，估摸着可以偷懒。\n软件用了同事推荐的OpenSCAD，通过代码的方式来进行建模。我基本上是一边查文档一边写，很容易就上手找到需要的功能写出来了。\n除了没有代码自动格式化这一点略有不习惯，代码逻辑支持实体的交并补操作，渲染后可以意见导出 stl 格式文档进行后续打印工作，实在是方便的很。\n放两张成果图，使用的是创想三维的 Ender-3 打印机。冬天材料热涨冷缩比较严重结果留下了两道印子，有点可惜。\n电池盒是圣诞节的时候那种细绳装饰灯的电池，考虑到亮度和分散光源，接了一个 COB 灯板。\n工程文件放在github上了。\n","date":"2021-01-12T00:00:00Z","permalink":"https://naizi.ch/2021/01/12/%E8%AF%95%E5%81%9A%E4%BA%86%E4%B8%80%E4%B8%AA%E6%98%8E%E6%97%A5%E6%96%B9%E8%88%9F%E7%9A%84%E5%B0%8F%E5%A4%9C%E7%81%AF/","title":"试做了一个明日方舟的小夜灯"},{"content":"通过使用 python-escpos 库，就可以和常见的 USB 热敏打印机通信来进行打印，不再赘述具体方法。\n但是 python-escpos 库并不是为 Windows 写的，实际在使用的时候就会出现许多的问题。\n一个常见的错误是\nValueError: No backend available\n根据Stackoverflow上的解答，应该是缺少 dll 文件，按解答中提供的链接地址下载安装就行了。\n但安装后会出现新的错误：\nNotImplementedError: Operation not supported or unimplemented on this platform\n所幸在 python-escpos 的 Github issue316中有人提供了解决方式。直接修改源代码，删去对应的异常捕捉，就能够正常使用了。\n此处留档以备不时之需。\n","date":"2020-07-07T00:00:00Z","permalink":"https://naizi.ch/2020/07/07/python-%E4%BD%BF%E7%94%A8-usb-%E7%83%AD%E6%95%8F%E6%89%93%E5%8D%B0%E6%9C%BA/","title":"Python 使用 USB 热敏打印机"},{"content":"疫情期间在家工作一直使用公司的 VPN，于是在公司电脑开了共享用来传输文件。但不知道为什么，公司-\u0026gt;家方向传文件很顺畅，反方向传文件时就经常会出现进度条走到末尾就停住，要多等一段时间才能传输结束的问题。\n虽然可以考虑用 OneDrive 这类网盘来进行同步，但这样的同步不够实时，而且毕竟要从三方服务器绕一圈，上传速度波动也很大。\n想到既然 Windows 10 支持了 OpenSSH，家里和公司电脑又都装了 WSL，也许可以用 rsync/scp 来解决这个问题。\n安装 OpenSSH Server Windows 10(1809) 虽然自带了 OpenSSH 的 Server 和 Client，但默认并没有安装。\n参照Microsoft 的文档给两台电脑都安装 OpenSSH：\nGet-WindowsCapability -Online | ? Name -like \u0026#39;OpenSSH*\u0026#39; # This should return the following output: Name : OpenSSH.Client~~~~0.0.1.0 State : NotPresent Name : OpenSSH.Server~~~~0.0.1.0 State : NotPresent # Install the OpenSSH Client Add-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0 # Install the OpenSSH Server Add-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0 # Both of these should return the following output: Path : Online : True RestartNeeded : False Start-Service sshd # OPTIONAL but recommended: Set-Service -Name sshd -StartupType \u0026#39;Automatic\u0026#39; # Confirm the Firewall rule is configured. It should be created automatically by setup. Get-NetFirewallRule -Name *ssh* # There should be a firewall rule named \u0026#34;OpenSSH-Server-In-TCP\u0026#34;, which should be enabled # If the firewall does not exist, create one New-NetFirewallRule -Name sshd -DisplayName \u0026#39;OpenSSH Server (sshd)\u0026#39; -Enabled True -Direction Inbound -Protocol TCP -Action Allow -LocalPort 22 这时候就可以从其中一台电脑向另一台发起 SSH 连接了。\n生成 SSH 密钥并部署 考虑到之后计划使用 rsync 传输，与 Linux 类似，我们可以使用密钥登陆的方式来避免每次都要输入密码。\n先设定作为 Client 的电脑：\n# 提示输入生成密钥的文件名，这里假设是 client_rsa ssh-keygen # 启动ssh-agent服务 Get-Service -Name ssh-agent | Set-Service -StartupType \u0026#39;Automatic\u0026#39; Start-Service ssh-agent # 导入密钥 ssh-add client_rsa 先通过密码登录的方式 SSH 连接到 Server 的电脑上：（注意替换成自己的 server_user 和 client_user）\nssh server_user@Server_ip mkdir C:\\Users\\server_user\\.ssh\\ scp C:\\Users\\client_user\\.ssh\\client_rsa.pub server_user@Server_ip:C:\\Users\\server_user\\.ssh\\authorized_keys 退出 SSH 会话，然后重新连接，这时应该已经不需要再输入密码了。\n设置到这里的时候踩到一个坑：如果 SSH 登录的 Server 用户是管理员身份的话，authorized_keys需要存到C:\\ProgramData\\ssh\\administrators_authorized_keys这个位置。\n不然的话此时 SSH 登录仍然会要求密码。\nssh server_user@Server_ip scp C:\\Users\\client_user\\.ssh\\client_rsa.pub server_user@Server_ip:C:\\ProgramData\\ssh\\administrators_authorized_keys # 修正ACL权限 $acl = Get-Acl C:\\ProgramData\\ssh\\administrators_authorized_keys $acl.SetAccessRuleProtection($true, $false) $administratorsRule = New-Object system.security.accesscontrol.filesystemaccessrule(\u0026#34;Administrators\u0026#34;,\u0026#34;FullControl\u0026#34;,\u0026#34;Allow\u0026#34;) $systemRule = New-Object system.security.accesscontrol.filesystemaccessrule(\u0026#34;SYSTEM\u0026#34;,\u0026#34;FullControl\u0026#34;,\u0026#34;Allow\u0026#34;) $acl.SetAccessRule($administratorsRule) $acl.SetAccessRule($systemRule) $acl | Set-Acl 之后对调 Client 和 Server 的身份再做一次同样的事情就可以了。\n进入 WSL 部署 rsync 只用 scp 存在着一定的局限性，若要使用 rsync 则需要依靠 WSL 了。\n依旧从 Client 开始设置：\ncd ~/.ssh cp /mnt/c/Users/client_user/.ssh/client_rsa ./client_rsa cp /mnt/c/Users/client_user/.ssh/client_rsa.pub ./client_rsa.pub chmod 600 client_rsa 转到 Server 上：\ncd ~/.ssh cp /mnt/c/Users/server_user/.ssh/authorized_keys ./authorized_keys 假设 Client 的 D 盘有个 testfile 的文件，测试 rsync：\n# --rsync-path=\u0026#34;wsl rsync\u0026#34; 用来指示Server通过wsl启动rsync环境 rsync -rtuv -e \u0026#34;ssh -i ~/.ssh/client_rsa\u0026#34; /mnt/d/testfile server_user@Server_ip:/mnt/d/ --rsync-path=\u0026#34;wsl rsync\u0026#34; 如果一切正常，应该不会提示输入密码，然后你能在 Server 的 D 盘看到这个文件。\n同样，对调 Client 和 Server 的身份再设定一次就可以双向操作了。\nEOF ","date":"2020-05-03T00:00:00Z","permalink":"https://naizi.ch/2020/05/03/windows-10-%E4%BD%BF%E7%94%A8-openssh--rsync/scp-%E5%90%8C%E6%AD%A5%E6%96%87%E4%BB%B6/","title":"Windows 10 使用 OpenSSH + Rsync/SCP 同步文件"},{"content":"有些 python 脚本任务对于树莓派来说还是负担太重了。毕竟性能上限摆在那里，也不能靠一个小小的 pi 承担太多。\n借此机会正好尝试一下 WSL(Windows Subsystem for Linux).\n安装 WSL 安装 WSL 并没有想象中的复杂。进入控制面板-\u0026gt;程序和功能-\u0026gt;启用或关闭 Windows 功能，勾选适用于Linux的Windows子系统，等待安装完毕，然后重启系统。\n重启完毕，开始菜单选择 MicrosoftStore，搜索 linux 就能够找到可供使用的 linux 发行版，我这里选择了 Ubuntu18.04LTS。\n应用安装完毕后，启动应用会要求设定基础的用户名和密码，接着，一个可供使用的 WSL 就准备就绪了。\n确保 crontab 服务 由于 WSL 并不会默认启动，而且当运行中的 WSL 的最后一个 bash 关闭后，就相当于关闭了整个子系统，那我们的 crontab 也就直接去世了。\n为了保持 crontab 常驻，需要一些措施。这里参考了Schedule Tasks Using Crontab on Windows 10 with WSL的方法，建立一个 crontab 服务的 Windows 启动项，每次系统启动后在后台常驻。\n首先进入 WSL，修改 sudoer，避免每次启动 crontab 服务时需要输入密码确认：\nsudo visudo\n在文件末尾加入\n%sudo ALL=NOPASSWD: /etc/init.d/cron start\n然后保存文件。回到 Windows，Win+R 打开运行，输入shell:startup打开启动文件夹，右键新建快捷方式，目标输入：\nC:\\Windows\\System32\\wsl.exe sudo /etc/init.d/cron start\n这样我们就能够保证 crontab 在每次 Windows 启动后常驻后台了。一切正常的话重启 Windows，在任务管理器能看到一个名称为 cron 的进程。\n使用 crontab 剩下的操作和在 linux 里使用 crontab 没有区别，唯一需要注意的是文件的路径。\n在 WSL 中，Windows 的 C 盘被挂载在/mnt/c目录下，D\\E\\F 以此类推，需要注意对应修改。\nEOF ","date":"2020-01-25T00:00:00Z","permalink":"https://naizi.ch/2020/01/25/windows-%E4%BD%BF%E7%94%A8-wsl-%E9%85%8D%E7%BD%AE-crontab-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/","title":"Windows 使用 WSL 配置 crontab 定时任务"},{"content":"逛微博看到了一些有意思的东西：山东卫视《国学小名士》第三季的节目，进行了一场 π(圆周率) 的飞花令。\n节目里选手们接到了小数点后 204 位，那，能不能更长一点？\n数据储备 首先需要有足够多的古诗词储备，不然程序生成的时候耗光弹药就显得非常尴尬了。\n非常感谢chinese-poetry这样的开源项目，积累了大量的已经结构化的古诗词数据。\n这里只用宋词部分的数据。\n算法逻辑 逻辑很简单粗暴：找出所有包含中文数字的词句进行汇总，然后按小数点后位数迭代 π 值随机取对应的诗词就行。\n整理诗词数据：\nimport json import re import os filelist = [ file for file in os.listdir(\u0026#39;./json\u0026#39;) if re.search(r\u0026#39;poet.song\u0026#39;, file) ] files = [ json.load(open(\u0026#39;./json/\u0026#39; + file, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8-sig\u0026#39;)) for file in filelist ] result = { \u0026#39;一\u0026#39;: [], \u0026#39;二\u0026#39;: [], \u0026#39;三\u0026#39;: [], \u0026#39;四\u0026#39;: [], \u0026#39;五\u0026#39;: [], \u0026#39;六\u0026#39;: [], \u0026#39;七\u0026#39;: [], \u0026#39;八\u0026#39;: [], \u0026#39;九\u0026#39;: [], \u0026#39;零\u0026#39;: [] } for file in files: for x in file: for y in x[\u0026#39;paragraphs\u0026#39;]: for z in [\u0026#39;一\u0026#39;, \u0026#39;二\u0026#39;, \u0026#39;三\u0026#39;, \u0026#39;四\u0026#39;, \u0026#39;五\u0026#39;, \u0026#39;六\u0026#39;, \u0026#39;七\u0026#39;, \u0026#39;八\u0026#39;, \u0026#39;九\u0026#39;, \u0026#39;零\u0026#39;]: if re.search(z, y): result[z] = result.get(z) + [ \u0026#39;{}\\n\\t\\t\\t\\t{}/{}\u0026#39;.format(y, x[\u0026#39;author\u0026#39;], x[\u0026#39;title\u0026#39;]) ] with open(\u0026#39;step.json\u0026#39;, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8-sig\u0026#39;) as f: f.write(json.dumps(result, ensure_ascii=False)) π 值计算 无脑套用了一下别人的代码：http://z-rui.github.io/post/2015/06/pi-digits/\ndef pidigits(): q, r, t, u, i = 1, 180, 60, 168, 2 while True: y = r // t yield y q, r, t, u, i = 10 * q * i * (2 * i - 1), 10 * u * ( q * (5 * i - 2) + r - y * t), t * u, u + 54 * (i + 1), i + 1 不停迭代 pidigits() 就能得到后一位小数数值。\n开始飞花令 测试一下迭代圆周率 1000 位\nimport json import sys from random import randint poets = json.load(open(\u0026#39;step.json\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8-sig\u0026#39;)) number = { 1: \u0026#39;一\u0026#39;, 2: \u0026#39;二\u0026#39;, 3: \u0026#39;三\u0026#39;, 4: \u0026#39;四\u0026#39;, 5: \u0026#39;五\u0026#39;, 6: \u0026#39;六\u0026#39;, 7: \u0026#39;七\u0026#39;, 8: \u0026#39;八\u0026#39;, 9: \u0026#39;九\u0026#39;, 0: \u0026#39;零\u0026#39; } n = 0 def pidigits(): q, r, t, u, i = 1, 180, 60, 168, 2 while True: y = r // t yield y q, r, t, u, i = 10 * q * i * (2 * i - 1), 10 * u * ( q * (5 * i - 2) + r - y * t), t * u, u + 54 * (i + 1), i + 1 while True: f = open(\u0026#39;result.md\u0026#39;, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8-sig\u0026#39;) for num in pidigits(): used = [] new = poets[number[num]].pop(randint(0, len(poets[number[num]]))) while new in used: new = poets[number[num]].pop(randint(0, len(poets[number[num]]))) print(num, number[num], new) f.write(\u0026#39;{}\\t{}\\t{}\\n\u0026#39;.format( num, number[num], new.replace(number[num], \u0026#39;`{}`\u0026#39;.format(number[num])))) used = used.append(new) n += 1 if n \u0026gt; 1000: f.close() sys.exit() EOF ","date":"2019-11-26T00:00:00Z","permalink":"https://naizi.ch/2019/11/26/%E6%9D%A5%E4%B8%80%E5%9C%BA%E5%9C%86%E5%91%A8%E7%8E%87%E7%9A%84%E9%A3%9E%E8%8A%B1%E4%BB%A4/","title":"来一场圆周率的飞花令"},{"content":"有生之年我最后居然是用 Shell 来填了分 P 的 TODO……\ncURL - 命令行下的文件传输工具 cURL 这个工具太过强大，我也不知道该怎么去解释它比较好。几乎所有的网络访问，上传下载，都能够使用 cURL 来完成。\n也难怪诸如 Chrome 和 Firefox 等浏览器，会支持复制网络访问为 cURL。而其实我也一直依靠这个功能，通过https://curl.trillworks.com/来快速写我的 python 爬虫。\n大部分的工作都可以直接靠右键复制为 cURL 来完成，所以只需要简单的查看下 cURL 的说明，便于进行一些小的修改就行。\n然后开始对照之前写的 python 脚本的逻辑，一步步转成 Shell 脚本。\njq - 命令行下的 JSON 处理工具 B 站 API 接口的各种返回数据以 JSON 为主，直接靠 awk/sed 手撸解析是一件很痛苦的事。所以我们需要用上 jq 这个工具减轻负担。\njq 解析 JSON 数据非常的便捷，比如获取分 P 数据时：\n{ \u0026#34;code\u0026#34;: 0, \u0026#34;message\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;ttl\u0026#34;: 1, \u0026#34;data\u0026#34;: [ { \u0026#34;cid\u0026#34;: 73802454, \u0026#34;page\u0026#34;: 1, \u0026#34;from\u0026#34;: \u0026#34;vupload\u0026#34;, \u0026#34;part\u0026#34;: \u0026#34;3\u0026#34;, \u0026#34;duration\u0026#34;: 66, \u0026#34;vid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;weblink\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;dimension\u0026#34;: { \u0026#34;width\u0026#34;: 1920, \u0026#34;height\u0026#34;: 1080, \u0026#34;rotate\u0026#34;: 0 } } ] } ↑ jq 的另一个作用就是格式化 json 数据，比如上面的代码就是通过cat result.json | jq .自动格式化出来的。\n要取得分 P 的 cid，我们可以： curl -sL 'https://api.bilibili.com/x/player/pagelist?aid=42038790\u0026amp;jsonp=jsonp' | jq -r '.data[0].cid'\n如果有多个分 P，我们可以这样取得所有的 cid： curl -sL 'https://api.bilibili.com/x/player/pagelist?aid=42038790\u0026amp;jsonp=jsonp' | jq -r '.data[].cid'\n真的是非常方便。\nsed - 支持正则表达式的流编辑器 考虑到 windows 上的兼容性，如果用视频标题做文件名，势必要排除/?!.*|:等特殊字符。这时我们就可以用 sed 来完成： curl -sL -H https://api.bilibili.com/x/web-interface/view?aid=42038790 | jq -r '.data.title' | sed 's/[/?!.*|:]//g'\n再后面我们会更多的用到 sed。(Flag)\n编写 Shell 脚本 $1 代表了命令行传给脚本的第一个参数，使用场景类似 bash download.sh av42038790 通过 sed，我们可以兼容 bash download.sh https://www.bilibili.com/video/av42038790?from=search\u0026amp;seid=3037567923943401758 的链接模式。\naid=`echo $1 | sed -e \u0026#39;s/.*av//g\u0026#39; -e \u0026#39;s/[a-zA-Z?/].*//g\u0026#39;` Shell 脚本中声明变量时等号前后都不能有空格，使用变量时在变量前加上$\npagelist=\u0026#39;https://api.bilibili.com/x/player/pagelist?aid=\u0026#39;$aid\u0026#39;\u0026amp;jsonp=jsonp\u0026#39; cids=`curl -sL $pagelist | jq -r \u0026#39;.data[].cid\u0026#39;` 这里的 cids 只是一个包含空格分隔的字符串123 234 345，为了让 Shell 正确计数，把它转为数组\ncids_arr=($cids) 这样一来通过${ #cids_arr[@] }就能够正确得出 cids 中的元素个数\n接下来通过 for 循环遍历 cids 中的元素，为了能同时计算元素的个数，需要另行计数：\npart=0 for cid in $cids do episode=$(( ++part )) #some code done Shell 中的 if else 判断以 if 开始，fi 结束：\nif [ \u0026#34;${#cids_arr[@]}\u0026#34; == \u0026#34;1\u0026#34; ] then filename=av$aid.$title.mp4 # 视频只有1P时，不标注分P else filename=av$aid.$title【P$episode】.mp4 # 多P视频标注分P fi 判断视频是 DASH 还是 FLV：\njson_url=\u0026#39;https://api.bilibili.com/x/player/playurl?avid=\u0026#39;$aid\u0026#39;\u0026amp;cid=\u0026#39;$cid\u0026#39;\u0026amp;qn=116\u0026amp;fnver=0\u0026amp;fnval=16\u0026amp;otype=json\u0026amp;type=\u0026#39; json=`curl -sL $json_url` dash=`echo $json | jq \u0026#39;.data|has(\u0026#34;dash\u0026#34;)\u0026#39;` durl=`echo $json | jq \u0026#39;.data|has(\u0026#34;durl\u0026#34;)\u0026#39;` 处理 DASH 视频：\nif [ \u0026#34;$dash\u0026#34; == \u0026#34;true\u0026#34; ] then vp=`echo $json | jq -r \u0026#39;.data.dash.video[0].baseUrl\u0026#39;` # 视频 ap=`echo $json | jq -r \u0026#39;.data.dash.audio[0].baseUrl\u0026#39;` # 音频 aria2c --args $vp --out ./v_$cid.m4s aria2c --args $vp --out ./a_$cid.m4s ffmpeg -i ./v_$cid.m4s -i ./a_$cid.m4s -c:v copy -c:a copy ./$filename rm *.m4s 处理 FLV 视频：\nelif [ \u0026#34;$durl\u0026#34; == \u0026#34;true\u0026#34; ] then flvs=`echo $json | jq -r \u0026#39;.data.durl[].url\u0026#39;` for flv in $flvs do echo \u0026#34;file \u0026#39;./\u0026#34;$flvname\u0026#34;\u0026#39;\u0026#34; \u0026gt;./merge_$cid.txt flvname=`echo $flv | sed -e \u0026#39;s/\\?.*//g\u0026#39; -e \u0026#39;s/.*\\///g\u0026#39;` aria2c --args $flv --out ./$flvname ffmpeg -safe 0 -f concat -i ./merge_$cid.txt -c copy ./$filename rm *.flv rm ./merge_$cid.txt 使用 shift shift 命令的作用是左移参数，举例来说，如果我们传给脚本 3 个参数 a,b,c，脚本接收到的参数为：\necho $1 $2 $3 a b c 当我们执行 shift 后\nshift echo $1 $2 $3 b c 这样就可以在循环中一直只处理$1，直到所有参数左移完毕。\n先判断没有参数时退出脚本：\nif [ $# -eq 0 ] then echo -e \u0026#34;-\u0026gt;Need AVID to download!\\n\u0026#34; exit 1 fi 加上 shift 和循环：\nuntil [ $# -eq 0 ] do aid=`echo $1 | sed -e \u0026#39;s/.*av//g\u0026#39; -e \u0026#39;s/[a-zA-Z?/].*//g\u0026#39;` #some code shift done 记得加上 Cookies 要获得高清源必须在访问 API 时加上 Cookies，cURL 要做到这点很简单。\n测试得知判断的关键是 Cookies 的如下键值： DedeUserID=; DedeUserID__ckMd5=; SESSDATA=; bili_jct=\nF12 打开浏览器，找到对应的键值，保存成 Cookies 的文本文件，然后修改代码：\ncookies=`cat ./cookies` curl -sL -H \u0026#34;Cookie: \u0026#34;$cookies aria2c --header=\u0026#34;Cookie: \u0026#34;$cookies 完整代码 #!/bin/sh IFS=$\u0026#39;\\n\u0026#39; if [ $# -eq 0 ] then echo -e \u0026#34;-\u0026gt;Need AVID to download!\\n\u0026#34; exit 1 fi until [ $# -eq 0 ] do aid=`echo $1 | sed -e \u0026#39;s/.*av//g\u0026#39; -e \u0026#39;s/[a-zA-Z?/].*//g\u0026#39;` cookies=`cat ./cookies` pagelist=\u0026#39;https://api.bilibili.com/x/player/pagelist?aid=\u0026#39;$aid\u0026#39;\u0026amp;jsonp=jsonp\u0026#39; echo -e \u0026#34;-\u0026gt;Getting video list: \\n\u0026#34;$pagelist cids=`curl -sL -H \u0026#34;Cookie: \u0026#34;$cookies $pagelist | jq -r \u0026#39;.data[].cid\u0026#39;` title=`curl -sL -H \u0026#34;Cookie: \u0026#34;$cookies \u0026#39;https://api.bilibili.com/x/web-interface/view?aid=\u0026#39;$aid | jq -r \u0026#39;.data.title\u0026#39; | sed \u0026#39;s/[/?!.*|:]//g\u0026#39;` cids_arr=($cids) echo -e \u0026#34;-\u0026gt;Found video pages: \u0026#34;${#cids_arr[@]} part=0 for cid in $cids do episode=$(( ++part )) echo -e \u0026#34;-\u0026gt;Download video page: \u0026#34;$episode if [ \u0026#34;${#cids_arr[@]}\u0026#34; == \u0026#34;1\u0026#34; ] then filename=av$aid.$title.mp4 else filename=av$aid.$title【P$episode】.mp4 fi json_url=\u0026#39;https://api.bilibili.com/x/player/playurl?avid=\u0026#39;$aid\u0026#39;\u0026amp;cid=\u0026#39;$cid\u0026#39;\u0026amp;qn=116\u0026amp;fnver=0\u0026amp;fnval=16\u0026amp;otype=json\u0026amp;type=\u0026#39; echo -e \u0026#34;-\u0026gt;Getting video source: \\n\u0026#34;$json_url json=`curl -sL -H \u0026#34;Cookie: \u0026#34;$cookies $json_url` dash=`echo $json | jq \u0026#39;.data|has(\u0026#34;dash\u0026#34;)\u0026#39;` durl=`echo $json | jq \u0026#39;.data|has(\u0026#34;durl\u0026#34;)\u0026#39;` if [ \u0026#34;$dash\u0026#34; == \u0026#34;true\u0026#34; ] then vp=`echo $json | jq -r \u0026#39;.data.dash.video[0].baseUrl\u0026#39;` ap=`echo $json | jq -r \u0026#39;.data.dash.audio[0].baseUrl\u0026#39;` echo -e \u0026#34;-\u0026gt;Downloading Video Dash\u0026#34; aria2c -x10 -k1M --file-allocation=none --auto-file-renaming=false --allow-overwrite=true $vp\\ --show-console-readout false --quiet \\ --header=\u0026#34;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0\u0026#34;\\ --header=\u0026#34;Accept: */*\u0026#34;\\ --header=\u0026#34;Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34;\\ --header=\u0026#34;Referer: https://www.bilibili.com/video/av\u0026#34;$aid\\ --header=\u0026#34;Origin: https://www.bilibili.com\u0026#34;\\ --header=\u0026#34;DNT: 1\u0026#34;\\ --header=\u0026#34;Connection: keep-alive\u0026#34;\\ --header=\u0026#34;Pragma: no-cache\u0026#34;\\ --header=\u0026#34;Cache-Control: no-cache\u0026#34;\\ --header=\u0026#34;Cookie: \u0026#34;$cookies \\ --out ./v_$cid.m4s echo -e \u0026#34;-\u0026gt;Downloading Audio Dash\u0026#34; aria2c -x10 -k1M --file-allocation=none --auto-file-renaming=false --allow-overwrite=true $ap\\ --show-console-readout false --quiet \\ --header=\u0026#34;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0\u0026#34;\\ --header=\u0026#34;Accept: */*\u0026#34;\\ --header=\u0026#34;Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34;\\ --header=\u0026#34;Referer: https://www.bilibili.com/video/av\u0026#34;$aid\\ --header=\u0026#34;Origin: https://www.bilibili.com\u0026#34;\\ --header=\u0026#34;DNT: 1\u0026#34;\\ --header=\u0026#34;Connection: keep-alive\u0026#34;\\ --header=\u0026#34;Pragma: no-cache\u0026#34;\\ --header=\u0026#34;Cache-Control: no-cache\u0026#34;\\ --header=\u0026#34;Cookie: \u0026#34;$cookies \\ --out ./a_$cid.m4s echo -e \u0026#34;-\u0026gt;Merge into file: \u0026#34;$filename ffmpeg -i ./v_$cid.m4s -i ./a_$cid.m4s -c:v copy -c:a copy\\ -y -hide_banner -loglevel panic \\ ./$filename echo -e \u0026#34;-\u0026gt;Removing temp files\\n\u0026#34; rm *.m4s elif [ \u0026#34;$durl\u0026#34; == \u0026#34;true\u0026#34; ] then flvs=`echo $json | jq -r \u0026#39;.data.durl[].url\u0026#39;` for flv in $flvs do flvname=`echo $flv | sed -e \u0026#39;s/\\?.*//g\u0026#39; -e \u0026#39;s/.*\\///g\u0026#39;` echo \u0026#34;file \u0026#39;./\u0026#34;$flvname\u0026#34;\u0026#39;\u0026#34; \u0026gt;./merge_$cid.txt echo \u0026#34;-\u0026gt;Downloading Video Part: \u0026#34;$flvname aria2c -x10 -k1M --file-allocation=none --auto-file-renaming=false --allow-overwrite=true $flv\\ --show-console-readout false --quiet \\ --header=\u0026#34;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0\u0026#34;\\ --header=\u0026#34;Accept: */*\u0026#34;\\ --header=\u0026#34;Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34;\\ --header=\u0026#34;Referer: https://www.bilibili.com/video/av\u0026#34;$aid\\ --header=\u0026#34;Origin: https://www.bilibili.com\u0026#34;\\ --header=\u0026#34;DNT: 1\u0026#34;\\ --header=\u0026#34;Connection: keep-alive\u0026#34;\\ --header=\u0026#34;Pragma: no-cache\u0026#34; --header=\u0026#34;Cache-Control: no-cache\u0026#34;\\ --header=\u0026#34;Cookie: \u0026#34;$cookies \\ --out ./$flvname done echo \u0026#34;-\u0026gt;Merge into file: \u0026#34;$filename ffmpeg -safe 0 -f concat -i ./merge_$cid.txt -c copy\\ -y -hide_banner -loglevel panic \\ ./$filename echo -e \u0026#34;-\u0026gt;Removing temp files\\n\u0026#34; rm *.flv rm ./merge_$cid.txt else echo -e \u0026#34;-\u0026gt;Error: Video not found!\\n\u0026#34; fi done shift done EOF 清晰度选择我觉得就真的没必要了吧.jpg\n但是 jq 毕竟是个第三方工具，难道真的不能用 awk/sed 来解析 json 吗？\n可以，但没必要。\n但今天就尝试一次，用 awk 和 sed 组合，替换掉 jq 的工作：\n# 获取cids cids=`curl -sL -H \u0026#34;Cookie: \u0026#34;$cookies $pagelist | sed \u0026#39;s/[{,}]/\\n/g\u0026#39; | awk -F: \u0026#39;/\u0026#34;cid\u0026#34;/ {print $2}\u0026#39;` # 获取视频标题 title=`curl -sL -H \u0026#34;Cookie: \u0026#34;$cookies \u0026#39;https://api.bilibili.com/x/web-interface/view?aid=\u0026#39;$aid | sed -e \u0026#39;s/[{}]//g\u0026#39; -e \u0026#39;s/,\u0026#34;/\\n\u0026#34;/g\u0026#39; | awk -F: \u0026#39;/\u0026#34;title\u0026#34;/ {print $2}\u0026#39; | sed -e \u0026#39;s/\u0026#34;//g\u0026#39; -e \u0026#39;s/[/?!.*|:]/-/g\u0026#39;` # 是否是DASH dash=`echo $json | sed -e \u0026#39;s/[{}]//g\u0026#39; -e \u0026#39;s/,\u0026#34;/\\n\u0026#34;/g\u0026#39; | awk \u0026#39;/\u0026#34;dash\u0026#34;/\u0026#39;` # 是否是FLV durl=`echo $json | sed -e \u0026#39;s/[{}]//g\u0026#39; -e \u0026#39;s/,\u0026#34;/\\n\u0026#34;/g\u0026#39; | awk \u0026#39;/\u0026#34;durl\u0026#34;/\u0026#39;` if [ \u0026#34;$dash\u0026#34; != \u0026#34;\u0026#34; ] then # 视频 DASH vp=`echo $json | sed -e \u0026#39;s/[{}]//g\u0026#39; -e \u0026#39;s/,\u0026#34;/\\n\u0026#34;/g\u0026#39; -e \u0026#39;s/\\]//g\u0026#39; | awk \u0026#39;/\u0026#34;video\u0026#34;/,/\u0026#34;audio\u0026#34;/\u0026#39; | awk \u0026#39;/\u0026#34;baseUrl\u0026#34;/\u0026#39; | sed -e \u0026#39;s/\u0026#34;baseUrl\u0026#34;://g\u0026#39; -e \u0026#39;s/\u0026#34;//g\u0026#39; -e \u0026#39;s/\\u0026/\\\u0026amp;/g\u0026#39; -e \u0026#39;s/\\\\\\\\//g\u0026#39; | awk \u0026#39;NR==1\u0026#39;` # 音频 DASH ap=`echo $json | sed -e \u0026#39;s/[{}]//g\u0026#39; -e \u0026#39;s/,\u0026#34;/\\n\u0026#34;/g\u0026#39; -e \u0026#39;s/\\]//g\u0026#39; | awk \u0026#39;/\u0026#34;audio\u0026#34;/,/\u0026#34;\u0026#34;/\u0026#39; | awk \u0026#39;/\u0026#34;baseUrl\u0026#34;/\u0026#39; | sed -e \u0026#39;s/\u0026#34;baseUrl\u0026#34;://g\u0026#39; -e \u0026#39;s/\u0026#34;//g\u0026#39; -e \u0026#39;s/\\u0026/\\\u0026amp;/g\u0026#39; -e \u0026#39;s/\\\\\\\\//g\u0026#39; | awk \u0026#39;NR==1\u0026#39;` elif [ \u0026#34;$durl\u0026#34; != \u0026#34;\u0026#34; ] then # FLV 视频 flvs=`echo $json | sed -e \u0026#39;s/[{}]//g\u0026#39; -e \u0026#39;s/,\u0026#34;/\\n\u0026#34;/g\u0026#39; -e \u0026#39;s/\\]//g\u0026#39; | awk \u0026#39;/\u0026#34;url\u0026#34;/\u0026#39; | sed -e \u0026#39;s/\u0026#34;url\u0026#34;://g\u0026#39; -e \u0026#39;s/\u0026#34;//g\u0026#39; -e \u0026#39;s/\\u0026/\\\u0026amp;/g\u0026#39; -e \u0026#39;s/\\\\\\\\//g\u0026#39;` else echo -e \u0026#34;-\u0026gt;Error: Video not found!\\n\u0026#34; fi ","date":"2019-11-16T00:00:00Z","permalink":"https://naizi.ch/2019/11/16/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E4%B8%8B%E8%BD%BD%E5%B7%A5%E5%85%B7-%E4%B8%89/","title":"哔哩哔哩下载工具 三"},{"content":"记录下折腾 Cmder 的过程。\n虽然群友安利了许久的 WSL 和 Powershell，但对于前两者的 GUI 我实在看不下去。也许他们真的很棒，但好用的工具似乎注定了不能拥有好看的 UI。\n而我，还是倾向于 UI 舒服的。毕竟只要它真的不是功能上缺胳膊少腿儿，剩下的事情，大部分都可以克服。\n再说了，不多折腾折腾，不多踩几个坑，多 Google 和 Stackoverflow 一下，你怎么会知道原来世界上还能有这种问题呢.jpg\n初始化 我们可以从Cmder 的主页下载它的最新版（当前是 v1.3.12）。为了避免之后和 Github 以及 Cygwin 附带的命令出现不同版本并存的问题，选择Download Mini。\n下载完毕后解压，先把 Cmder 添加到右键菜单，方便之后随时调用。在解压目录打开一个管理员权限的 Powershell：\nCmder.exe /REGISTER ALL\n接下来先放着 Cmder 不管，继续装 Git for windows。\n从Git for windows 的主页下载最新版，安装基本都是默认选项，需要注意的是：\nAdjusting your PATH enviroment选择Use Git from the Windows Command Prompt Configuring the line ending conversions选择Checkout Windows-style, commit Unix-style line endings Configuing the terminal emulator to use with Git Bash选择Use MinTTY 额外选项可以默认也可以不选，安装完成后在任意目录右键，应该能看见Git Bash Here和Git GUI Here的选项。\n接着继续，安装 Cygwin。\n在Cygwin 官网下载对应版本（64-bit/32-bit），双击执行，默认选项即可。\n在Choose A Download Site这步，我们可以添加清华大学的镜像源https://mirrors.tuna.tsinghua.edu.cn/cygwin/来提升软件包的下载速度，然后点击下一步。\n在 Search 中搜索 wget，下拉菜单将 Skip 替换成其中一个版本安装，这是之后安装 apt-cyg 需要的依赖。另外检查 gwak、tar、bzip2 这几个包是否安装（不是 Skip 就对了）。\n有需要的话可以自己选择还要安装哪些命令，不过这些都可以之后再改，先接着继续下一步默认安装就可以了。\n折腾 现在我们有了 Cmder+Github+Cygwin，接下来把他们整一起。\ngit 比较方便，打开控制面板，选择系统和安全-\u0026gt;系统-\u0026gt;高级系统设置-\u0026gt;环境变量，在用户变量里选择Path-\u0026gt;编辑，如果是默认安装的话，应该会有一条C:\\Program Files\\Git\\usr\\bin的记录，如果没有可以手动添加。\n然后打开 Cmder，输入 git 并回车，检查是否能够调用 git。\nCygwin 按照同样的方式加入系统环境变量，默认路径是C:\\cygwin64\\bin，如果修改了安装路径需要对应修改。\n接着安装 apt-cyg，有了它就可以像 Ubuntu 管理软件包一样随意 install 需要的命令了。\napt-cyg 的项目主页是 https://github.com/transcode-open/apt-cyg ，在 Release 页面下载最新版，解压将apt-cyg文件移动到C:\\cygwin64\\bin，打开 cygwin 终端：\napt-cyg install nano\n测试 apt-cyg 是否正常工作。\n为了解决中文编码问题，在 Cygwin 终端窗口右键选择Options，选择Text，更改locale为zh_CN，Character set为UTF-8。\n然后 nano 或者 vi 编辑~/.bashrc文件，在文件最后添加：\nexport LC_ALL=zh_CN.UTF-8 export LC_CTYPE=zh_CN.UTF-8 export LANG=zh_CN.UTF-8 为了 Cygwin 和 Cmder 整合后，能够识别当前工作目录，通过 apt-cyg 安装 chere 命令：\napt-cyg install chere\n然后还是编辑~/.bashrc，追加内容：[参考 1]\nif [ -n \u0026#34;${ConEmuWorkDir}\u0026#34; ]; then cd \u0026#34;$ConEmuWorkDir\u0026#34; fi Cygwin 中 C 盘的路径映射为/cygdrive/c，如果觉得太长的话，可以在 cygwin 终端里修改/etc/fstab或者直接修改C:\\cygwin64\\etc\\fstab:\n# /etc/fstab # # This file is read once by the first process in a Cygwin process tree. # To pick up changes, restart all Cygwin processes. For a description # see https://cygwin.com/cygwin-ug-net/using.html#mount-table # This is default anyway: # none /cygdrive cygdrive binary,posix=0,user 0 0 none / cygdrive binary 0 0 之后 C 盘映射到/c，D 盘映射到/d，以此类推。\n以上设置完可以算是告一段落了，接着把 Cygwin 整进 Cmder 里。\n打开 Cmder，右键选择Settings，选择Startup-\u0026gt;Tasks。\n点击\u0026rsquo;+\u0026lsquo;号添加新的 Task，Task Name填一个能区分出是 Cygwin 的，比如Cygwin::bash，Task parameters填写/icon C:\\cygwin64\\Cygwin-Terminal.ico，在Commands中填写set CHERE_INVOKING=1 \u0026amp; C:\\cygwin64\\Cygwin.bat -c \u0026quot;/bin/xhere /bin/bash.exe --login -i '%V'\u0026quot;参考 2\n然后勾选上Default task for new console和Taskbar jump lists。回到Startup，选择Specified named task-\u0026gt;Cygwin::bash。\n这样一来 Cmder 的默认终端就是 Cygwin 了，git 命令和 windows 本身的支持也没有问题。\n进一步调整 General-\u0026gt;Fonts 先解决编码问题，选择General-\u0026gt;Fonts-\u0026gt;Unicode ranges-\u0026gt;CJK: 2E80-9FC3;AC00-D7A3;F900-FAFF;FE30-FE4F;FF01-FF60;FFE0-FFE6;-\u0026gt;Apply。\nFont charset还是保持 ANSI，否则 Cmder 会报错Failed to create font然后 fail back 回缺省字体。\n然后选择Startup-\u0026gt;Environment，添加如下内容：\nset PATH=%ConEmuBaseDir%\\Scripts;%PATH% set LANG=zh_CN.UTF8 接着是字体，中文字体真的太少了，好看的就更少了。（有一说一，我觉得，确实，是这样的）\n选了 Powerline Fonts：\ngit clone https://github.com/powerline/fonts.git\n我单独装了Noto Mono for Powerline，也可以选择执行install.ps1直接安装全部的字体。\n在Main console font选了Noto Mono for Powerline后，中文还是会 fail back 成宋体，这里勾上Alternative font，选择微软雅黑 Light，个人感觉不违和，能看。\n其他勾选上Monospace和Compress long strings to fit space。\nGeneral-\u0026gt;Size \u0026amp; Pos 将Width改为 80%，Height改为 70%，这样 Cmder 启动会自动根据显示器大小调整窗口大小。\nGeneral-\u0026gt;Background 设置Background Image和Darkening可以给终端添加图片背景并调整图片透明度，我就敬谢不敏了。\nGeneral-\u0026gt;Confirm 去除Confirm creating new console/tab和Confirm tab duplicating的勾选，这两个太烦人了。\nFeatures-\u0026gt;Transparency Alpha transparency可以调整终端窗口本身的透明度，我这里直接拖到了最右边不透明。屡次截图终端映出了背后的内容总是让我心有余悸。\nKeys \u0026amp; Macro-\u0026gt;Paste 确保两个Paste mode都是Multi lines，避免行为不一致。\n其他 Cmder 有自己的user_alias(\u0026ldquo;Cmder/config/user_alias.cmd\u0026rdquo;) 可以很方便的设定一些常用命令，可以在 cmd 或者 powershell 终端里使用，但是不能和 Cygwin 通用。Cygwin 需要 Alias 的话还是得老老实实编辑~/.bashrc。\nCmder 可以作为 Sublime Text 的终端来使用，Sublime 安装 Terminal 插件，设置终端路径为 Cmder 安装路径即可。默认呼出终端的快捷键是 Ctrl+Shift+T。\nCygwin 有个已知问题，Ctrl+方向键没有绑定操作，需要手动添加，方法是编辑~/.inputrc添加两行内容\u0026quot;\\e[1;5C\u0026quot;: forward-word和\u0026quot;\\e[1;5D\u0026quot;: backward-word。[参考 3]\n如果之前已经生成了 SSH KEY 的话，需要手动复制到C:\\cygwin64\\home\\\u0026lt;user name\u0026gt;\\.ssh或者直接指定 ssh key 才能让 git 识别到。\nEOF","date":"2019-10-19T00:00:00Z","permalink":"https://naizi.ch/2019/10/19/%E9%85%8D%E7%BD%AE-cmder-%E6%95%B4%E5%90%88-cygwin-%E4%B8%8E-github/","title":"配置 Cmder 整合 Cygwin 与 Github"},{"content":"\u0026ndash;\u0026gt; jojo，python 的能力是有极限的。\n\u0026ndash;\u0026gt; 我从短暂的人生当中学到一件事\u0026hellip;\u0026hellip;\n\u0026ndash;\u0026gt; 越是玩弄代码，就越会发现 python 的不足\u0026hellip;\u0026hellip;\n\u0026ndash;\u0026gt; 除非超越 python。\n你到底想说什么？\n\u0026ndash;\u0026gt; 吔我 bash 啦！\n起因 原因其实很简单，工作上需要使用后台导入些数据。\n吭哧吭哧把原始数据整理完，搞成 csv 了，点个“导入”，给我来了个报错：\n单次导入只支持 1000 条 崽啊，9102 年末了，我 csv 里面近百万条数据，你跟我说一次 1000？我不下班啦？\n然而优秀的底层员工是不会抱怨这些事情的，行吧，我自己切表总行了吧。\n尝试 python 切割 先用 python 瞎糊了一个：\ndatas = {} for n, line in enumerate(open(\u0026#39;test.csv\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8-sig\u0026#39;)): if datas.get(n//1000): datas[n//1000] = datas[n//1000] + [line] else: datas[n//1000] = [line] for k,v in datas.items(): with open(\u0026#39;test-{}.csv\u0026#39;.format(k), \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8-sig\u0026#39;) as f: f.write(\u0026#39;\u0026#39;.join(v)) 凑合着用了，顺便再写了个脚本把切好的文件自动导入到后台，把工作做完了。\n但是回过头了，就开始嫌弃 python 不够快了。\n虽然很明显原因在于我（毕竟瞎糊凑合用），想看能不能更快一点。\n于是想起了 bash，想起了 split 和 xargs。\n换成 bash 要切割文件的话 split 的确很方便：\nsplit test.csv -l 1000 -d -a 3 test__\n-d -a 3指定了按 3 位数递增添加后缀，这样就能产生 test001 ~ test999 命名的切割好的文件。\n但新的问题也来了，切割完需要全部加上文件扩展名：\nmv test_001 test-001.csv\n但手工操作量还是太大，这时候我们就需要 xargs 了：\nls | grep test__ | xargs -n1 -I file mv file file.csv\nls | grep test__筛选了所有缺少扩展名的文件，管道命令传给 xargs 后，-n1代表一次接受一个参数，-I file告诉 xargs 后续命令中的file全部用参数值替换。\n比如只有一个文件的时候，ls | grep test__只有一个结果test__001，xargs 接收到参数，将file替换成test__001，实际执行内容就是：\nmv test001 test001.csv\n将他们组合一下：\nsplit -l 1000 test.csv -d -a 3 test**\u0026amp;\u0026amp; ls | grep test** | xargs -n1 -I file mv file file.csv\n回车执行，1 秒都不需要，爽死了。\n人类是懒惰的动物 但这样还是需要自己手打需要切割的文件名，不够爽。尝试把代码再变长一点：\nls | grep .csv$ | sed \u0026rsquo;s/.csv//g\u0026rsquo; | xargs -n1 -I file split -l 1000 file.csv -d -a 3 file**\u0026amp;\u0026amp; ls | grep** | xargs -n1 -I file mv file file.csv\n以管道命令分割解释一下：\nls 列出当前目录下所有文件和子目录 grep .csv$ 筛选扩展名是 csv 的所有文件 sed 's/.csv//g' 去除扩展名，只留文件名 xargs -n1 -I file split -l 1000 file.csv -d -a 3 file__ 切割所有的文件 ls 列出当前目录下所有文件和子目录 grep __ 筛选文件名包含__的文件（上一步切割好的文件） xargs -n1 -I file mv file file.csv 加上扩展名 爽又死了。\nEOF 尝试在 windows 上（Cmder+Github）做类似的操作，发现远没有在虚拟机（Ubuntu）里执行快，垃圾微软.jpg\n","date":"2019-10-18T00:00:00Z","permalink":"https://naizi.ch/2019/10/18/jojopython-%E7%9A%84%E8%83%BD%E5%8A%9B%E6%98%AF%E6%9C%89%E6%9E%81%E9%99%90%E7%9A%84/","title":"jojo，python 的能力是有极限的"},{"content":"之前从同事那里二手买了个咕咕机，当玩具玩。享受了几天使用 APP 打印各种沙雕照片和表情包带来的乐趣后，它毫无意外的开始吃灰，就和桌子旁边的树莓派一样染上历史的颜色。\n还是拿出来用用吧……\n咕咕机 APP 里的一部分订阅号的确有点意思，比如订阅每天天气，早上 8 点自动打印一条天气内容之类的。那么拿来订阅微博更新好像也没什么不对的。\n反正一天有 12 小时在公司，闲着也是闲着，不定时的来一段小纸条也不错。\n开发者申请 为了做到这些，首先要去咕咕机的开发者页面申请 APPKEY。填写必要的信息然后提交申请就行了。等了一周左右申请就通过了。\n拿到 APPKEY 之后，可以查阅官方给的文档，可用的 API 其实不多，更多还是要靠自己去生成内容。\nGitHub上也有其他开发者写的 SDK，可以不用自己重复按照官方文档造轮子。\nRSS 打个比方，订阅小狐狸的 B 站动态。\n熟练的打开小狐狸的空间，F12，刷新，过滤 XHR，找到 API 接口https://api.vc.bilibili.com/dynamic_svr/v1/dynamic_svr/space_history。B 站的动态有多种类型，需要根据类型判断爬取的内容。\n['data']['cards']['desc']['type']的值表明了动态是何种类型，比如 1 是指转发，2 是带图动态，4 是纯文字动态，8 是投稿视频推送。\n在 ['data']['cards']['card'] 中是一串 JSON 数据，动态的文本内容根据上面不同的类型存在不同的键值里，比如['dynamic']、['item']['content']、['item']['description']这几个位置。\n图片存储 只有文本内容的纸条太单调了，信息量也不够，还是需要能够同时打印图片内容。但图片打印会增加打印时间和下载时间，折衷选择只保存附带图片的第一张。\n为了保持目录整洁，图片数据全部用 sqlite3 存储。\n内容更新 为了避免重复打印浪费纸张，每次爬取数据时需要判断是否有新的内容。\n建数据表，只存储必要的时间、日期、文字内容和图片数据，加上动态的 ID 作为主键来进行去重。\nCREATE TABLE IF NOT EXISTS 白上吹雪Official ( day VARCHAR, _id VARCHAR PRIMARY KEY UNIQUE, msg VARCHAR, pic BLOB, title VARCHAR); 然后人工插入一条 id 为 0 的数据，用来记录是否获取到新内容，每次先单独查询这一行，有新数据再取出内容进行打印。\nPOST 请求打印 利用之前提到的 SDK，将文字和图片的复合内容整合后一起 POST 给服务器。\n小花样 为了区分普通的带图动态和视频投稿的推送，仿照动态的样式给视频投稿的图像加上了角标。同时因为咕咕机采用的是 WiFi 打印，为了减小文件体积，POST 数据前对图片尺寸进行缩小。\nfrom pymobird import Content from pymobird import Content bird = SimplePymobird(appkey, device_id, user_id) content = Content() content.add_text(\u0026#39;【{}】\u0026#39;.format(uname)) # 用户名 content.add_text(time.strftime(\u0026#39;%Y-%m-%d %H:%M\u0026#39;,time.gmtime(int(day)))) # 日期 content.add_text(\u0026#39;https://t.bilibili.com/{}\u0026#39;.format(_id)) # 链接 content.add_text(msg) # 文字内容 from PIL import Image from PIL import ImageDraw from PIL import ImageFont img = Image.open(\u0026#39;peitu.jpg\u0026#39;) img.thumbnail((400, 400), Image.ANTIALIAS) font = ImageFont.truetype(\u0026#39;SourceHanSansCN-Regular.otf\u0026#39;, 22) draw = ImageDraw.Draw(img) draw.rectangle( (268, 15, 368, 47), fill=(250, 115, 150), outline=(250, 140, 160)) draw.text((274, 14), \u0026#39;投稿视频\u0026#39;, \u0026#39;#FFFFFF\u0026#39;, font=font) img.save(\u0026#39;peitu.png\u0026#39;, \u0026#39;PNG\u0026#39;) content.add_image(\u0026#39;peitu.png\u0026#39;) result = bird.print_multi_part_content(content) Crontab 定时任务 开 SSH 把脚本扔进富有历史感的树莓派。\ncrontab -e\n*/5 * * * * python3 bilibili_fubuki.py\n完整代码 #!/usr/bin/python ## -*- coding: utf-8 -*- import json import os import re import requests import sqlite3 import time ## bilibili uname = \u0026#39;白上吹雪 Official\u0026#39; uid = \u0026#39;332704117\u0026#39; ## memobird appkey = \u0026#39;\u0026#39; device_id = \u0026#39;\u0026#39; user_id = \u0026#39;\u0026#39; headers = { \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:69.0) Gecko/20100101 Firefox/69.0\u0026#39;, \u0026#39;Accept\u0026#39;: \u0026#39;application/json, text/plain, */*\u0026#39;, \u0026#39;Accept-Language\u0026#39;: \u0026#39;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#39;, \u0026#39;Origin\u0026#39;: \u0026#39;https://space.bilibili.com\u0026#39;, \u0026#39;DNT\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;Connection\u0026#39;: \u0026#39;keep-alive\u0026#39;, \u0026#39;Referer\u0026#39;: \u0026#39;https://space.bilibili.com/\u0026#39;, } newfile = not os.path.exists(\u0026#39;bilibili_{}.sqlite\u0026#39;.format(uname)) db = sqlite3.connect(\u0026#39;bilibili_{}.sqlite\u0026#39;.format(uname), isolation_level=None) cur = db.cursor() cur.execute(\u0026#39;\u0026#39;\u0026#39; CREATE TABLE IF NOT EXISTS {} ( day VARCHAR, _id VARCHAR PRIMARY KEY UNIQUE, msg VARCHAR, pic BLOB, title VARCHAR);\u0026#39;\u0026#39;\u0026#39;.format(uname)) if newfile: cur.execute(\u0026#39;\u0026#39;\u0026#39;INSERT INTO {} VALUES ( ?, ?, ?, ?, ? );\u0026#39;\u0026#39;\u0026#39;.format(uname), (None, \u0026#39;0\u0026#39;, \u0026#39;1\u0026#39;, None, None)) def bili_pic(link): file = requests.get(link, headers=headers) return file.content def main(): params = ( (\u0026#39;visitor_uid\u0026#39;, \u0026#39;0\u0026#39;), (\u0026#39;host_uid\u0026#39;, \u0026#39;{}\u0026#39;.format(uid)), (\u0026#39;offset_dynamic_id\u0026#39;, \u0026#39;0\u0026#39;), ) response = requests.get( \u0026#39;https://api.vc.bilibili.com/dynamic_svr/v1/dynamic_svr/space_history\u0026#39;, headers=headers, params=params) result = json.loads(response.content) if result.get(\u0026#39;code\u0026#39;) != 0: print(result.get(\u0026#39;message\u0026#39;)) return False for card in result[\u0026#39;data\u0026#39;][\u0026#39;cards\u0026#39;]: card_time = card[\u0026#39;desc\u0026#39;][\u0026#39;timestamp\u0026#39;] card_id = card[\u0026#39;desc\u0026#39;][\u0026#39;dynamic_id_str\u0026#39;] card_type = card[\u0026#39;desc\u0026#39;][\u0026#39;type\u0026#39;] data = json.loads(card[\u0026#39;card\u0026#39;]) if card_type == 8: title = data[\u0026#39;title\u0026#39;] pic = data[\u0026#39;pic\u0026#39;] text = data[\u0026#39;dynamic\u0026#39;] elif card_type == 4: title = None pic = None text = data[\u0026#39;item\u0026#39;][\u0026#39;content\u0026#39;] elif card_type == 2: title = None if data[\u0026#39;item\u0026#39;].get(\u0026#39;pictures\u0026#39;): pic = data[\u0026#39;item\u0026#39;][\u0026#39;pictures\u0026#39;][0][\u0026#39;img_src\u0026#39;] text = data[\u0026#39;item\u0026#39;][\u0026#39;description\u0026#39;] elif card_type == 1: title = None pic = None text = data[\u0026#39;item\u0026#39;][\u0026#39;content\u0026#39;] else: print(card_time, card_id, card_type) continue img = bili_pic(pic) if pic else None cur.execute( \u0026#39;\u0026#39;\u0026#39;INSERT OR REPLACE INTO {} VALUES ( ?, ?, ?, ?, ? );\u0026#39;\u0026#39;\u0026#39;.format( uname), (card_time, card_id, text, img, title)) new = cur.execute( \u0026#39;\u0026#39;\u0026#39;SELECT COUNT(_id) FROM {};\u0026#39;\u0026#39;\u0026#39;.format(uname)).fetchone() old = cur.execute( \u0026#39;\u0026#39;\u0026#39;SELECT msg FROM {} WHERE _id = 0;\u0026#39;\u0026#39;\u0026#39;.format(uname)).fetchone() if int(new[0]) == int(old[0]): return False cur.execute(\u0026#39;\u0026#39;\u0026#39;UPDATE {} SET msg = ? WHERE _id = 0\u0026#39;\u0026#39;\u0026#39;.format(uname), (str(new[0]), )) limit = int(new[0]) - int(old[0]) if limit \u0026lt; 0: return False limit = limit if limit \u0026lt; 1 else 1 from pymobird import Content from pymobird import SimplePymobird bird = SimplePymobird(ak=appkey, device_id=device_id, user_id=user_id) data = cur.execute( \u0026#39;\u0026#39;\u0026#39;SELECT day, _id, msg, pic, title FROM {} ORDER BY _id DESC LIMIT {};\u0026#39;\u0026#39;\u0026#39; .format(uname, limit)).fetchall() for dynamic in data[::-1]: day, _id, msg, pic, title = dynamic content = Content() content.add_text(\u0026#39;【{}】\u0026#39;.format(uname)) content.add_text(time.strftime(\u0026#39;%Y-%m-%d %H:%M\u0026#39;,time.gmtime(int(day)))) content.add_text(\u0026#39;https://t.bilibili.com/{}\u0026#39;.format(_id)) content.add_text(msg) if pic: with open(\u0026#39;{}.jpg\u0026#39;.format(uname), \u0026#39;wb\u0026#39;) as f: f.write(pic) img = Image.open(\u0026#39;{}.jpg\u0026#39;.format(uname)) img.thumbnail((400, 400), Image.ANTIALIAS) if title: from PIL import Image from PIL import ImageDraw from PIL import ImageFont content.add_text(title) font = ImageFont.truetype(\u0026#39;SourceHanSansCN-Regular.otf\u0026#39;, 22) draw = ImageDraw.Draw(img) draw.rectangle((268, 15, 368, 47), fill=(250, 115, 150), outline=(250, 140, 160)) draw.text((274, 14), \u0026#39;投稿视频\u0026#39;, \u0026#39;#FFFFFF\u0026#39;, font=font) img.save(\u0026#39;{}.png\u0026#39;.format(uname), \u0026#39;PNG\u0026#39;) content.add_image(\u0026#39;{}.png\u0026#39;.format(uname)) result = bird.print_multi_part_content(content) print(result) time.sleep(5) if __name__ == \u0026#39;__main__\u0026#39;: main() EOF ","date":"2019-10-02T00:00:00Z","permalink":"https://naizi.ch/2019/10/02/rss-%E5%92%95%E5%92%95%E6%9C%BA/","title":"RSS 咕咕机"},{"content":"主要解决一些之前遇到的坑，填一些留下的 TODO。\nVegas 不支持 HEVC 编码 思路很简单，对下载下来的m4s先读一遍编码，看是不是 HEVC 格式的，如果是就在转码的时候用libx264编码，不是就粗暴的 copy 视频流。\n暂时不打算加上判断其他视频流格式的代码，遇到再说。\n通过 ffprobe 判断编码 因为之前很少接触视频转码，也没什么机会用 ffmpeg。在判断 HEVC 编码这一步的时候，想着用类似ffmpeg -args | find \u0026quot;stream\u0026quot;的方式来取得视频编码。\n可能是环境问题，没成功，而且还要另写正则匹配文本有些麻烦。查了一下改用 ffprobe。\nffprobe.exe -v error -select_streams v:0 -show_entries stream=codec_name -of default=nokey=1:noprint_wrappers=1 v.m4s \u0026raquo; ./t.txt\nffmpeg 合并 flv ffmpeg 的问题主要出现在合并 flv 上，dash 视频倒没有什么问题。\n采用-f concat -i file.list的方式合并遇到了路径问题。因为听取了建议“下载的文件最好单独放个目录，直接下在脚本根目录就会很乱”。\n所有的文件都下载在了子文件夹里，比如./down。在下载 flv 分段的时候，文件的目录结构就类似：\n.. ffmpeg.exe /down /down/file.list /down/part1.flv /down/part2.flv\nffmpeg 的命令写成：\nffmpeg -safe 0 -hide_banner -f concat -i ./down/file.list -c copy ./down/finish.mp4\n问题来了，file.list 里该怎么写，我原本以为应该是：\nfile \u0026lsquo;./down/part1.flv\u0026rsquo; file \u0026lsquo;./down/part2.flv\u0026rsquo; file \u0026lsquo;./down/part3.flv\u0026rsquo;\n然而这样 ffmpeg 会报错找不到文件，根据错误信息里提示的文件路径，应该改成\nfile \u0026lsquo;part1.flv\u0026rsquo; file \u0026lsquo;part2.flv\u0026rsquo; file \u0026lsquo;part3.flv\u0026rsquo;\n看来 file.list 里的根目录是 file.list 所在目录。\n通过子进程加速下载 音频和视频同时下载。因为原本用 os.system 的方式会阻塞，改用 subprocess.Popen 子进程，然后在 ffmpeg 合并前阻塞两个子进程，确保下载完毕再进行合并。\n单个任务的话就用上面的方式，然后开启多进程同时执行多个任务。但是这样又遇到了新的问题：\n尝试多进程和 pyinstaller 的坑 因为最后要打包成 exe 给其他人用，毕竟没必要让每个人都装一个 python 环境来跑脚本。\n在打包过程中发现，虽然 py 脚本能够正确执行，但是打包完成的 exe 反而变成了一个 fork 炸弹，会无限的产生子进程直到让系统宕机。\n如是三次之后 Google 了一下，pyinstaller 和 multiprocessing 相性不合，使用 mulitprocessing.Process 和 mulitprocessing.Pool 的代码在 pyinstaller 编译后就会出现这个问题。\n给出的解决方法只适用于 python2 版本，而我用的是 python3.7，摊手。\n改用 threading 绕过问题 既然不能用多进程，那就用多线程好了。\n而且实际上我也的确是先用的 threading 库，遇到了问题才想的用 multiprocessing。\n原因是 threading 的场合，我编译 exe 完成，测试的时候想直接关闭窗口，发现做不到。\n结论而且这不算什么问题，比起 fork 炸弹要可接受的多了，而且一个下载工具，本来就没有必要在中途退出。\n最后上了线程池from multiprocessing.dummy import Pool as ThreadPool，幸好这样并不会和 pyinstaller 冲突。\n放弃写配置文件 计划把 ffmpeg 和 aria2c 的配置单独存文件的来着，想想又要增加代码量，而且几乎不会去动这些配置，还是作罢了。\n硬编码不也挺好么.jpg\n完整代码 #!/usr/bin/python ## -*- coding: utf-8 -*- import arrow import json import os import re import requests import subprocess from lxml import etree from multiprocessing.dummy import Pool as ThreadPool today = arrow.utcnow().format(\u0026#39;YYYY-MM-DD\u0026#39;) if os.path.exists(\u0026#39;./{}\u0026#39;.format(today)): pass else: os.mkdir(\u0026#39;./{}\u0026#39;.format(today)) session = requests.session() session.headers = { \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0\u0026#39;, \u0026#39;Accept\u0026#39;: \u0026#39;application/json, text/plain, */*\u0026#39;, \u0026#39;Accept-Language\u0026#39;: \u0026#39;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#39;, \u0026#39;Referer\u0026#39;: \u0026#39;https://www.bilibili.com/video/av42038790?from=search\u0026amp;seid=4077958841119274554\u0026#39;, \u0026#39;Origin\u0026#39;: \u0026#39;https://www.bilibili.com\u0026#39;, \u0026#39;DNT\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;Connection\u0026#39;: \u0026#39;keep-alive\u0026#39;, \u0026#39;Pragma\u0026#39;: \u0026#39;no-cache\u0026#39;, \u0026#39;Cache-Control\u0026#39;: \u0026#39;no-cache\u0026#39;, } with open(\u0026#39;cookies\u0026#39;, \u0026#39;r\u0026#39;) as f: cookies = f.read() session.headers[\u0026#39;cookie\u0026#39;] = cookies def videocid(aid=42038790, part=1): params = ( (\u0026#39;aid\u0026#39;, aid), (\u0026#39;jsonp\u0026#39;, \u0026#39;jsonp\u0026#39;), ) response = session.get( \u0026#39;https://api.bilibili.com/x/player/pagelist\u0026#39;, params=params, ) # cookies=cookies) result = json.loads(response.content) cid = result[\u0026#39;data\u0026#39;][part - 1][\u0026#39;cid\u0026#39;] return cid def videourl(aid=42038790, cid=73802454): params = ( (\u0026#39;avid\u0026#39;, aid), (\u0026#39;cid\u0026#39;, cid), (\u0026#39;qn\u0026#39;, \u0026#39;112\u0026#39;), (\u0026#39;fnver\u0026#39;, \u0026#39;0\u0026#39;), (\u0026#39;fnval\u0026#39;, \u0026#39;16\u0026#39;), (\u0026#39;type\u0026#39;, \u0026#39;\u0026#39;), (\u0026#39;otype\u0026#39;, \u0026#39;json\u0026#39;), ) response = session.get( \u0026#39;https://api.bilibili.com/x/player/playurl\u0026#39;, params=params,) # cookies=cookies) result = json.loads(response.content) if result.get(\u0026#39;data\u0026#39;) is None: response = session.get( \u0026#39;https://api.bilibili.com/pgc/player/web/playurl\u0026#39;, params=params,) # cookies=cookies) result = json.loads(response.content) playinfo = result.get(\u0026#39;result\u0026#39;) else: playinfo = result.get(\u0026#39;data\u0026#39;) if playinfo is None: print(aid, \u0026#39;Not Found\\n\u0026#39;) return False if playinfo.get(\u0026#39;dash\u0026#39;): aids = [x[\u0026#39;id\u0026#39;] for x in playinfo[\u0026#39;dash\u0026#39;][\u0026#39;audio\u0026#39;]] aurl = playinfo[\u0026#39;dash\u0026#39;][\u0026#39;audio\u0026#39;][aids.index(max(aids))][\u0026#39;baseUrl\u0026#39;] vids = [x[\u0026#39;id\u0026#39;] for x in playinfo[\u0026#39;dash\u0026#39;][\u0026#39;video\u0026#39;]] vurl = playinfo[\u0026#39;dash\u0026#39;][\u0026#39;video\u0026#39;][vids.index(max(vids))][\u0026#39;baseUrl\u0026#39;] ap = subprocess.Popen( \u0026#39;\u0026#39;\u0026#39;aria2c.exe -x10 -k1M --file-allocation=none --auto-file-renaming=false \u0026#34;{aurl}\u0026#34;\\ --header=\u0026#34;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0\u0026#34;\\ --header=\u0026#34;Accept: */*\u0026#34;\\ --header=\u0026#34;Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34;\\ --header=\u0026#34;Referer: https://www.bilibili.com/video/av{aid}\u0026#34;\\ --header=\u0026#34;Origin: https://www.bilibili.com\u0026#34;\\ --header=\u0026#34;DNT: 1\u0026#34;\\ --header=\u0026#34;Connection: keep-alive\u0026#34;\\ --header=\u0026#34;Pragma: no-cache\u0026#34;\\ --header=\u0026#34;Cache-Control: no-cache\u0026#34;\\ --out ./{today}/{cid}_a.m4s\u0026#39;\u0026#39;\u0026#39;.format(today=today, aurl=aurl, aid=aid, cid=cid), shell=True) vp = subprocess.Popen( \u0026#39;\u0026#39;\u0026#39;aria2c -x10 -k1M --file-allocation=none --auto-file-renaming=false \u0026#34;{vurl}\u0026#34;\\ --header=\u0026#34;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0\u0026#34;\\ --header=\u0026#34;Accept: */*\u0026#34;\\ --header=\u0026#34;Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34;\\ --header=\u0026#34;Referer: https://www.bilibili.com/video/av{aid}\u0026#34;\\ --header=\u0026#34;Origin: https://www.bilibili.com\u0026#34;\\ --header=\u0026#34;DNT: 1\u0026#34;\\ --header=\u0026#34;Connection: keep-alive\u0026#34;\\ --header=\u0026#34;Pragma: no-cache\u0026#34;\\ --header=\u0026#34;Cache-Control: no-cache\u0026#34;\\ --out ./{today}/{cid}_v.m4s\u0026#39;\u0026#39;\u0026#39;.format(today=today, vurl=vurl, aid=aid, cid=cid), shell=True) ap.wait() vp.wait() vt = subprocess.Popen( \u0026#39;\u0026#39;\u0026#39;ffprobe.exe -v error -select_streams v:0 -show_entries stream=codec_name\\ -of default=nokey=1:noprint_wrappers=1\\ ./{today}/{cid}_v.m4s \u0026gt;\u0026gt; ./{today}/{cid}_t.txt\u0026#39;\u0026#39;\u0026#39;.format(today=today, cid=cid), shell=True) vt.wait() with open(\u0026#39;./{today}/{cid}_t.txt\u0026#39;.format(today=today, cid=cid), \u0026#39;r\u0026#39;) as f: v_type = str(f.read()).replace(\u0026#39;\\n\u0026#39;, \u0026#39;\u0026#39;) if v_type == \u0026#39;hevc\u0026#39;: fp = subprocess.Popen( \u0026#39;\u0026#39;\u0026#39;ffmpeg -n -hide_banner -i ./{today}/{cid}_v.m4s -i ./{today}/{cid}_a.m4s -c:v libx264 -c:a copy\\ ./{today}/av{aid}.mp4\u0026#39;\u0026#39;\u0026#39;.format(today=today, cid=cid, aid=aid), shell=True) else: fp = subprocess.Popen( \u0026#39;\u0026#39;\u0026#39;ffmpeg -n -hide_banner -i ./{today}/{cid}_v.m4s -i ./{today}/{cid}_a.m4s -c:v copy -c:a copy\\ ./{today}/av{aid}.mp4\u0026#39;\u0026#39;\u0026#39;.format(today=today, cid=cid, aid=aid), shell=True) os.remove(\u0026#39;./{today}/{cid}_t.txt\u0026#39;.format(today=today, cid=cid)) fp.wait() os.remove(\u0026#39;./{today}/{cid}_a.m4s\u0026#39;.format(today=today, cid=cid)) os.remove(\u0026#39;./{today}/{cid}_v.m4s\u0026#39;.format(today=today, cid=cid)) elif playinfo.get(\u0026#39;durl\u0026#39;): vlink = [x[\u0026#39;url\u0026#39;] for x in playinfo[\u0026#39;durl\u0026#39;]] with open(\u0026#39;./{today}/{aid}_merge.txt\u0026#39;.format(today=today, aid=aid), \u0026#39;a\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as t: for p, link in enumerate(vlink): t.write( \u0026#34;\u0026#34;\u0026#34;file \u0026#39;./av{aid}_{p}.flv\u0026#39;\\n\u0026#34;\u0026#34;\u0026#34;.format(aid=aid, p=p)) for p, link in enumerate(vlink): subprocess.check_call( \u0026#39;\u0026#39;\u0026#39;aria2c.exe -x10 -k1M --file-allocation=none --auto-file-renaming=false \u0026#34;{link}\u0026#34;\\ --header=\u0026#34;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0\u0026#34;\\ --header=\u0026#34;Accept: */*\u0026#34;\\ --header=\u0026#34;Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34;\\ --header=\u0026#34;Referer: https://www.bilibili.com/video/av{aid}\u0026#34;\\ --header=\u0026#34;Origin: https://www.bilibili.com\u0026#34;\\ --header=\u0026#34;DNT: 1\u0026#34;\\ --header=\u0026#34;Connection: keep-alive\u0026#34;\\ --header=\u0026#34;Pragma: no-cache\u0026#34; --header=\u0026#34;Cache-Control: no-cache\u0026#34;\\ --out ./{today}/av{aid}_{p}.flv\u0026#39;\u0026#39;\u0026#39;.format(today=today, link=link, aid=aid, p=p), shell=True) fp = subprocess.Popen( \u0026#39;\u0026#39;\u0026#39;ffmpeg -safe 0 -hide_banner -f concat -i ./{today}/{aid}_merge.txt -c copy\\ ./{today}/av{aid}.mp4\u0026#39;\u0026#39;\u0026#39;.format(today=today, aid=aid), shell=True) fp.wait() os.remove(\u0026#39;./{today}/{aid}_merge.txt\u0026#39;.format(today=today, aid=aid)) for p, link in enumerate(vlink): os.remove( \u0026#39;./{today}/av{aid}_{p}.flv\u0026#39;.format(today=today, aid=aid, p=p)) def main(): pool = ThreadPool(processes=5) with open(\u0026#39;down.txt\u0026#39;, \u0026#39;r\u0026#39;) as f: aids = re.findall(r\u0026#39;av(\\d+)\u0026#39;, f.read()) for x in aids: pool.apply_async(videourl, (x, videocid(x))) pool.close() pool.join() if __name__ == \u0026#39;__main__\u0026#39;: main() TODO 部分视频的视频流是 HEVC 编码而不是 x264，Windows 读不出 MP4 缩略图，考虑要不要判断自动转码。 aria2 和 ffmpeg 的参数单独存文件方便修改，不然每次都要重新编译 exe。 分 P 选择和清晰度选择 EOF ","date":"2019-04-30T00:00:00Z","permalink":"https://naizi.ch/2019/04/30/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E4%B8%8B%E8%BD%BD%E5%B7%A5%E5%85%B7-%E4%BA%8C/","title":"哔哩哔哩下载工具 二"},{"content":"给哔哩哔哩周刊组写的下载工具。每次都要下载十几个视频，一个个手动来实在是太麻烦了。\n看了下，发现下载最高清一路的视频源还是需要 cookie 认证，写不来登录，只能用 dirty 的方式读 cookie 文件了。\n分析 获取视频需要知道视频的 av 号和视频 id，api 接口里分别是avid和cid，有了两者之后就可以通过 api 获得视频不同清晰度的 url 地址。\nB 站现在新视频全部使用了 dash，但是老视频没有 dash，还是单个 flv，两者在 api 上返回有区别，前者是dash字段，后者是durl字段，需要判断是哪一种视频流。\n对于 dash，音频和视频流分割两路，都是 m4s 格式，下载后需要合并。而 flv 根据视频时长会有多个分段文件，同样也需要合并。\n代码 #!/usr/bin/python ## -*- coding: utf-8 -*- import json import os import re import requests from lxml import etree session = requests.session() session.headers = { \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0\u0026#39;, \u0026#39;Accept\u0026#39;: \u0026#39;application/json, text/plain, */*\u0026#39;, \u0026#39;Accept-Language\u0026#39;: \u0026#39;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#39;, # \u0026#39;Referer\u0026#39;: \u0026#39;https://www.bilibili.com/video/av42038790\u0026#39;, \u0026#39;Origin\u0026#39;: \u0026#39;https://www.bilibili.com\u0026#39;, \u0026#39;DNT\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;Connection\u0026#39;: \u0026#39;keep-alive\u0026#39;, \u0026#39;Pragma\u0026#39;: \u0026#39;no-cache\u0026#39;, \u0026#39;Cache-Control\u0026#39;: \u0026#39;no-cache\u0026#39;, } with open(\u0026#39;cookies\u0026#39;, \u0026#39;r\u0026#39;) as f: cookies = f.read() session.headers[\u0026#34;cookie\u0026#34;] = cookies def videocid(aid=42038790, part=1): params = ( (\u0026#39;aid\u0026#39;, aid), (\u0026#39;jsonp\u0026#39;, \u0026#39;jsonp\u0026#39;), ) response = session.get( \u0026#39;https://api.bilibili.com/x/player/pagelist\u0026#39;, params=params, ) # cookies=cookies) result = json.loads(response.content) cid = result[\u0026#39;data\u0026#39;][part - 1][\u0026#39;cid\u0026#39;] return cid def videourl(aid=42038790, cid=73802454): params = ( (\u0026#39;avid\u0026#39;, aid), (\u0026#39;cid\u0026#39;, cid), (\u0026#39;qn\u0026#39;, \u0026#39;112\u0026#39;), (\u0026#39;fnver\u0026#39;, \u0026#39;0\u0026#39;), (\u0026#39;fnval\u0026#39;, \u0026#39;16\u0026#39;), (\u0026#39;type\u0026#39;, \u0026#39;\u0026#39;), (\u0026#39;otype\u0026#39;, \u0026#39;json\u0026#39;), ) response = session.get( \u0026#39;https://api.bilibili.com/x/player/playurl\u0026#39;, params=params,) # cookies=cookies) result = json.loads(response.content) if result.get(\u0026#39;data\u0026#39;) is None: response = session.get( \u0026#39;https://api.bilibili.com/pgc/player/web/playurl\u0026#39;, params=params,) # cookies=cookies) result = json.loads(response.content) playinfo = result.get(\u0026#39;result\u0026#39;) else: playinfo = result.get(\u0026#39;data\u0026#39;) if playinfo is None: print(aid, \u0026#39;Not Found\\n\u0026#39;) return False if playinfo.get(\u0026#39;dash\u0026#39;): vids = [x[\u0026#39;id\u0026#39;] for x in playinfo[\u0026#39;dash\u0026#39;][\u0026#39;video\u0026#39;]] vurl = playinfo[\u0026#39;dash\u0026#39;][\u0026#39;video\u0026#39;][vids.index( max(vids))][\u0026#39;baseUrl\u0026#39;] aids = [x[\u0026#39;id\u0026#39;] for x in playinfo[\u0026#39;dash\u0026#39;][\u0026#39;audio\u0026#39;]] aurl = playinfo[\u0026#39;dash\u0026#39;][\u0026#39;audio\u0026#39;][aids.index( max(aids))][\u0026#39;baseUrl\u0026#39;] os.system(\u0026#39;\u0026#39;\u0026#39;aria2c -x10 -k1M --file-allocation=none \u0026#34;{}\u0026#34; --header=\u0026#34;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0\u0026#34; --header=\u0026#34;Accept: */*\u0026#34; --header=\u0026#34;Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34; --header=\u0026#34;Referer: https://www.bilibili.com/video/av{}\u0026#34; --header=\u0026#34;Origin: https://www.bilibili.com\u0026#34; --header=\u0026#34;DNT: 1\u0026#34; --header=\u0026#34;Connection: keep-alive\u0026#34; --header=\u0026#34;Pragma: no-cache\u0026#34; --header=\u0026#34;Cache-Control: no-cache\u0026#34; --out {}_v.m4s\u0026#39;\u0026#39;\u0026#39;.format(vurl, aid, cid)) os.system(\u0026#39;\u0026#39;\u0026#39;aria2c.exe -x10 -k1M --file-allocation=none \u0026#34;{}\u0026#34; --header=\u0026#34;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0\u0026#34; --header=\u0026#34;Accept: */*\u0026#34; --header=\u0026#34;Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34; --header=\u0026#34;Referer: https://www.bilibili.com/video/av{}\u0026#34; --header=\u0026#34;Origin: https://www.bilibili.com\u0026#34; --header=\u0026#34;DNT: 1\u0026#34; --header=\u0026#34;Connection: keep-alive\u0026#34; --header=\u0026#34;Pragma: no-cache\u0026#34; --header=\u0026#34;Cache-Control: no-cache\u0026#34; --out {}_a.m4s\u0026#39;\u0026#39;\u0026#39;.format(aurl, aid, cid)) os.system( \u0026#39;\u0026#39;\u0026#39;ffmpeg -i {}_v.m4s -i {}_a.m4s -c:v copy -c:a copy -strict experimental av{}.mp4\u0026#39;\u0026#39;\u0026#39;.format(cid, cid, aid)) os.remove(\u0026#39;{}_a.m4s\u0026#39;.format(cid)) os.remove(\u0026#39;{}_v.m4s\u0026#39;.format(cid)) elif playinfo.get(\u0026#39;durl\u0026#39;): vlink = [x[\u0026#39;url\u0026#39;] for x in playinfo[\u0026#39;durl\u0026#39;]] print(vlink) for p, link in enumerate(vlink): os.system(\u0026#39;\u0026#39;\u0026#39;aria2c.exe -x10 -k1M --file-allocation=none \u0026#34;{}\u0026#34; --header=\u0026#34;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0\u0026#34; --header=\u0026#34;Accept: */*\u0026#34; --header=\u0026#34;Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34; --header=\u0026#34;Referer: https://www.bilibili.com/video/av{}\u0026#34; --header=\u0026#34;Origin: https://www.bilibili.com\u0026#34; --header=\u0026#34;DNT: 1\u0026#34; --header=\u0026#34;Connection: keep-alive\u0026#34; --header=\u0026#34;Pragma: no-cache\u0026#34; --header=\u0026#34;Cache-Control: no-cache\u0026#34; --out av{}_{}.flv\u0026#39;\u0026#39;\u0026#39;.format(link, aid, aid, p)) with open(\u0026#39;merge.txt\u0026#39;, \u0026#39;a\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as t: for x in os.listdir(\u0026#39;.\u0026#39;): if str(aid) in x: t.write(\u0026#34;file \u0026#39;{}\u0026#39;\\n\u0026#34;.format(x)) os.system(\u0026#39;ffmpeg -f concat -i merge.txt -c copy av{}.mp4\u0026#39;.format(aid)) os.remove(\u0026#39;merge.txt\u0026#39;) for x in os.listdir(\u0026#39;.\u0026#39;): if x.endswith(\u0026#39;.flv\u0026#39;): pass os.remove(x) def main(): with open(\u0026#39;down.txt\u0026#39;, \u0026#39;r\u0026#39;) as f: aids = re.findall(r\u0026#39;av(\\d+)\u0026#39;, f.read()) for x in aids: videourl(x, videocid(x)) if __name__ == \u0026#39;__main__\u0026#39;: main() TODO 部分视频的视频流是 HEVC 编码而不是 x264，Windows 读不出 MP4 缩略图，考虑要不要判断自动转码。 aria2 和 ffmpeg 的参数单独存文件方便修改，不然每次都要重新编译 exe。 分 P 选择和清晰度选择 EOF ","date":"2019-04-07T00:00:00Z","permalink":"https://naizi.ch/2019/04/07/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E4%B8%8B%E8%BD%BD%E5%B7%A5%E5%85%B7/","title":"哔哩哔哩下载工具"},{"content":"因为树莓派用了官方系统，原本在 Arch 上利用KMSCON来回显中文字符的方式不可行了，沉痛悼念。\n不会编译是罪魁祸首，而且包依赖关系看得头大，实在不想自己解决。\n前情提要 因为 tty 设备不支持 CJK 字符，原本 crontab 任务只要重定向输出到KMSCON模拟的 pts 设备上就能正常显示中文，现在不得不回归起点。\n选择只有两种：\n研究怎么在 debian 上把KMSCON编译过去 研究怎么在图形界面输出工作用脚本的日志 然后KMSCON的编译依赖实在有点多，在 debian 内的包名又都不一样。本来就只会按照教程 ./configure、make、make install三步走的我实在是应付不来。\n结果只能当KMSCON从来不存在，在图形界面寻找解决办法。\n变通法 搜索之后发现的确有从终端弹图形界面的方式，只需要指定显示设备就行了：\nDISPLAY=:0.0 command\n因为我的目的只是需要一个终端窗口，所以：\n\u0026gt; crontab -e --- @reboot sleep 30 \u0026amp;\u0026amp; DISPLAY=:0.0 /usr/bin/lxterminal 这样便会在系统启动之后自动启动一个终端窗口，分配一个 pts 的设备，因为是第一个终端窗口所以一定是 pts/0\n再把剩下的定时脚本输出全部重定向到 /dev/pts/0 就行了\nEOF 感觉还是会有回到 Arch 的一天，Arch 真香。\n","date":"2019-01-10T00:00:00Z","permalink":"https://naizi.ch/2019/01/10/%E6%B2%A1%E6%9C%89-kmscon-%E7%9A%84%E7%AC%AC%E4%B8%80%E5%A4%A9%E6%83%B3%E4%BB%96/","title":"没有 KMSCON 的第一天，想他"},{"content":"微博注册了个小号，为了看看都是什么牛鬼蛇神在微博里推送信息流广告，尝试抓取一下。\n虽然有YAWF（Yet Another Weibo Filter）这样好用的脚本可以屏蔽广告，但屏蔽了就看不到了。\n找到 API 接口 F12 切换到 Network，在首页刷新页面，筛选捕捉到 api 接口https://weibo.com/aj/mblog/fsearch。\n新建标签页访问，去掉不必要的参数（包括一堆用来指定上下文区间和已读分界线的 id），只留下必要的部分。\n然后直接上代码开始爬取内容：\nheaders = { \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (X11; Linux x86_64; rv:64.0) Gecko/20100101 Firefox/64.0\u0026#39;, \u0026#39;Accept\u0026#39;: \u0026#39;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\u0026#39;, \u0026#39;Accept-Language\u0026#39;: \u0026#39;en-US,en;q=0.5\u0026#39;, \u0026#39;DNT\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;Connection\u0026#39;: \u0026#39;keep-alive\u0026#39;, \u0026#39;Upgrade-Insecure-Requests\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;Cache-Control\u0026#39;: \u0026#39;max-age=0\u0026#39;, \u0026#39;Cookie\u0026#39;: cookie } params = ( (\u0026#39;ajwvr\u0026#39;, \u0026#39;6\u0026#39;), (\u0026#39;pre_page\u0026#39;, \u0026#39;0\u0026#39;), (\u0026#39;page\u0026#39;, \u0026#39;1\u0026#39;), (\u0026#39;pagebar\u0026#39;, \u0026#39;0\u0026#39;), ) response = requests.get(\u0026#39;https://weibo.com/aj/mblog/fsearch\u0026#39;, headers=headers, params=params) 返回数据是 json 结构，在data字段里存放了页面内容，这里用 lxml 库解析，保存 html 文件进行下一步。\nimport json from lxml import etree result = json.loads(response.content) html = etree.HTML(result[\u0026#39;data\u0026#39;]) with open(\u0026#39;feed.html\u0026#39;, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8-sig\u0026#39;) as f: f.write(etree.tostring(html, encoding=\u0026#39;unicode\u0026#39;)) CSS 筛选广告内容 打开保存的 html，格式化一下代码，找到存在feedtype=\u0026quot;ad\u0026quot;属性的节点（因为不是每次获取都会有信息流广告，所以可能需要获取很多次）。\n然后继续往下看子节点，直到找到具体的微博链接：\n获取此节点的 xpath：\u0026quot;//div[@feedtype]//a[@action-history='rec=1']/@action-data\u0026quot;\n结合正则表达式提取链接：\nimport re html = etree.HTML(result[\u0026#39;data\u0026#39;]) links = html.xpath(\u0026#34;//div[@feedtype]//a[@action-history=\u0026#39;rec=1\u0026#39;]/@action-data\u0026#34;) for link in links: adver = re.findall(r\u0026#39;url=([^\u0026amp;]+)\u0026amp;\u0026#39;, link) with open(\u0026#39;adver.list\u0026#39;, \u0026#39;a\u0026#39;, encoding=\u0026#39;utf-8-sig\u0026#39;) as f: f.write(str(adver)+\u0026#39;\\n\u0026#39;) 最后通过 crontab 设置成定时任务自动监测。\n* * * * * python weibo_adver.py 自动更新 cookie 高频率的连续访问可能会造成微博提示帐号异常，而且运行时间久了 cookie 也会过期，需要自动重新登录获取 cookie。\n微博的自动登录轮子很多，不用自己另写。cookie 过期的判断就比较粗暴了，如果读取返回的 json 抛出异常，就可以认为是 cookie 过期造成的。\n另外测试发现，不带 cookie 的 api 访问是会返回正常的 json 数据的（但不包含 html 内容）。\nimport os def login(username, password): \u0026#34;\u0026#34;\u0026#34;somecode balabala\u0026#34;\u0026#34;\u0026#34; with open(\u0026#39;cookies\u0026#39;,\u0026#39;w\u0026#39;) as f: f.write(cookies) def main(): if os.path.exists(\u0026#39;./cookies\u0026#39;): with open(\u0026#39;./cookies\u0026#39;, \u0026#39;r\u0026#39;) as f: cookie = f.read() else: return False \u0026#34;\u0026#34;\u0026#34;somecode balabala\u0026#34;\u0026#34;\u0026#34; response = requests.get(\u0026#39;https://weibo.com/aj/mblog/fsearch\u0026#39;, headers=headers, params=params) try: result = json.loads(response.content) except json.decoder.JSONDecodeError: login(username, password) return False \u0026#34;\u0026#34;\u0026#34;somecode balabala\u0026#34;\u0026#34;\u0026#34; if __name__ == \u0026#34;__main__\u0026#34;: main() EOF 就结果而言效果还不错，但也发现信息流广告里还会有一些关注了的博主的正常微博内容，可以考虑和自己的关注列表对比来筛除。\n","date":"2019-01-05T00:00:00Z","permalink":"https://naizi.ch/2019/01/05/%E5%BE%AE%E5%8D%9A%E4%BF%A1%E6%81%AF%E6%B5%81%E5%B9%BF%E5%91%8A%E6%8A%93%E5%8F%96/","title":"微博信息流广告抓取"},{"content":"为了让吃灰的树莓派重新开始工作，这回不瞎折腾了，直接用官方系统。\n安装 按照官方教程采用 NOOBS 安装，当然也可以选择用镜像安装，不论哪一种，选择 ↓\nRaspbian Stretch with desktop and recommended software\n安装完成后，首次进入图形界面，选择首选项中的 Raspberry Pi Configuration ，在 Interfaces 书签页启用 SSH, VNC，之后就可以不用另接键鼠了。\n记得在 Localisation 书签页设定好 WiFi Country。\n连接 WiFi 因为公司 WiFi 使用了 WPA-EAP 协议，树莓派不显示热点，让我一度以为树莓派不能连接此类 WiFi。后来在这篇文章的帮助下，通过修改 wpa_supplicant.conf 连接成功，但是 WiFi 列表中对应 SSID 选项为灰色不可点击，迷。\n修改 /etc/wpa_supplicant/wpa_supplicant.conf\nctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 country=CN network={ ssid=\u0026#34;OfficeWiFiSSID\u0026#34; key_mgmt=WPA-EAP identity=\u0026#34;username\u0026#34; password=\u0026#34;password\u0026#34; } 软件更新 更换软件源，这个不多说了，国内推荐 中国科学技术大学 、 清华大学 、 网易开源镜像站 的镜像。\n在 apt 更新前，先删除不必要的软件。反正周也是要卸载的，没必要让他们下载安装更新。\nsudo apt-get remove --purge python3-pygame python-pygame scratch nuscratch claws-mail smartsim sonic-pi minecraft-pi python-minecraftpi wolfram-engine scratch bluej nodered greenfoot scratch2 libreoffice libreoffice-base libreoffice-core chromium-browser thonny python3-thonny python-sense-emu python3-sense-emu python-sense-emu-doc sense-emu-tools sudo apt-get autoremove sudo apt-get update sudo apt-get dist-upgrade 卸载这部分应用后，会有一部分文件残留，通过 VNC 远程进去打开以下三个目录\n/usr/share/applications/\n/usr/share/raspi-ui-overrides/applications/\n/usr/share/mimelnk/application/\n在三个目录里找到图标显示失效的文件，删掉它们。\n自动获取树莓派 IP 接下来遇到的问题是，可能是因为联网设备实在太多，公司 WiFi 分配的 IP 地址短期内是和 MAC 绑定不变的，但假如长时间未连接，重新连接就会发分配不同的 IP。\n导致 SSH 记住 IP 并没有什么用，只能每次用 VNC 或者 nmap 扫描网段找到树莓派的地址。\nGoogle 后参考 这篇文章 设置，让树莓派每次 IP 变动后自动发送邮件通知自己。\nsudo apt-get install ssmtp mailutils\nnano /etc/ssmtp/ssmtp.conf\nroot=youremail@gmail.com mailhub=smtp.gmail.com:587 AuthUser=youremail@gmail.com AuthPass=yourpassword UseTLS=YES UseSTARTTLS=YES AuthMethod=LOGIN nano /home/pi/checkip.sh\n#!/bin/bash MYIP=`ifconfig | grep -Eo \u0026#39;inet (addr:)?([0-9]*\\.){3}[0-9]*\u0026#39; | grep -Eo \u0026#39;([0-9]*\\.){3}[0-9]*\u0026#39; | grep -v \u0026#39;127.0.0.1\u0026#39;`; TIME=`date`; LASTIPFILE=\u0026#39;/home/pi/.last_ip_addr\u0026#39;; LASTIP=`cat ${LASTIPFILE}`; if [[ ${MYIP} != ${LASTIP} ]] then if [[ ${MYIP} = \u0026#39;\u0026#39; ]] then echo \u0026#34;LOST\u0026#34; else echo \u0026#34;Sending E-mail..\u0026#34; echo -e \u0026#34;Hello\\n\\nTimestamp = ${TIME}\\nIP = ${MYIP}\\n\\nBye\u0026#34; | \\ /usr/bin/mail -s \u0026#34;[INFO] Raspberrypi New IP\u0026#34; youremail@gmail.com; echo ${MYIP} \u0026gt; ${LASTIPFILE}; fi else echo \u0026#34;No IP change!\u0026#34; fi chmod +x checkip.sh\ncrontab -e\n*/30 * * * * /home/pi/checkip.sh EOF 于是树莓派终于可以一边通电一边吃灰了。\n","date":"2018-12-08T00:00:00Z","permalink":"https://naizi.ch/2018/12/08/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B-raspberry-pi/","title":"从零开始 Raspberry Pi"}]